{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include\n",
    "import argparse\n",
    "import os, imp, sys\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import copy, math\n",
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my script\n",
    "sys.path.append('../')\n",
    "from data import get_dataset, get_num_classes\n",
    "from preprocess import get_transform\n",
    "from utils import *\n",
    "import models\n",
    "import quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = '/home/rusci/Work/quantized_neural_networks/results/Imagenet_ARM/mobilenetv2_test2/checkpoint.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pretrained\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(checkpoint_file):\n",
    "#            results.load(os.path.join(checkpoint_file, 'results.csv'))\n",
    "    checkpoint_file = os.path.join(\n",
    "        checkpoint_file, 'model_best.pth.tar')\n",
    "if os.path.isfile(checkpoint_file):\n",
    "    checkpoint_loaded = torch.load(checkpoint_file)\n",
    "    print('Model pretrained' )\n",
    "else:\n",
    "    print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['config', 'quantizer', 'val_prec1', 'model', 'epoch', 'fold_type', 'regime', 'add_config', 'best_prec1', 'state_dict'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = checkpoint_loaded['config']\n",
    "activ_bits = model_config['activ_bits']\n",
    "activ_type = model_config['activ_type']\n",
    "dataset = model_config['dataset']\n",
    "input_dim = model_config['input_dim']\n",
    "input_size = input_dim\n",
    "num_classes = model_config['num_classes']\n",
    "type_quant = model_config['type_quant']\n",
    "weight_bits = model_config['weight_bits']\n",
    "width_mult = model_config['width_mult']\n",
    "additional_config = ''\n",
    "quant_add_config = checkpoint_loaded['add_config']\n",
    "fold_type = checkpoint_loaded['fold_type']\n",
    "quantizer_load = checkpoint_loaded['quantizer']\n",
    "state_dict =  checkpoint_loaded['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_quant = model_config['type_quant']\n",
    "weight_bits = model_config['weight_bits']\n",
    "activ_bits = model_config['activ_bits']\n",
    "fold_type = 'ICN'\n",
    "quant_add_config = checkpoint_loaded['add_config']\n",
    "dummy_input = torch.Tensor(1,3,224,224)\n",
    "input_size = model_config['input_dim']\n",
    "dataset = model_config['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate fake-quantized MobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenetv2(activ_type='learned', act_bits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.module():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Folding:  False Batch Folding Delay:  0 Type ICN\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "Supported activation layer but no method is here yet!\n",
      "<class 'models.imagenet.mobilenetv2.InvertedResidual'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'> not supported yet!\n",
      "PerLayerAsymPACT chennel with fixed batch\n"
     ]
    }
   ],
   "source": [
    "quantizer = quantization.QuantOp(model, quant_type = type_quant, weight_bits = weight_bits,bias_bits =32, \\\n",
    "                                 batch_fold_delay=0,batch_fold_type=fold_type, act_bits=activ_bits, \\\n",
    "                                 add_config=quant_add_config, dummy_input = dummy_input  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Scale(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py:209: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "input_eval_transform = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "print(input_eval_transform)\n",
    "val_data = get_dataset(dataset, 'val', input_eval_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=16, shuffle=False,\n",
    "    num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(data_loader, model,  epoch=0, training=False, quantizer=None):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    model.eval()\n",
    "    #model = model.cuda()\n",
    "    \n",
    "    max_i = 1\n",
    "    min_i = -1\n",
    "    bit_i = 8\n",
    "    n_steps = (2**bit_i)-1\n",
    "    eps = (max_i-min_i) / n_steps\n",
    "    \n",
    "    for i, (inputs, target) in enumerate(data_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = Variable(inputs.cuda(), volatile=not training)\n",
    "        target_var = Variable(target)\n",
    "        \n",
    "        input_var = input_var.clamp(min_i,max_i).div(eps).round()\n",
    "        \n",
    "        if quantizer is not None:\n",
    "            input_var = input_var.mul(eps)\n",
    "            quantizer.store_and_quantize(training=False )\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        if type(output) is list:\n",
    "            output = output[0]\n",
    "        values, indices = output.max(1)\n",
    "        #print(indices, target)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if quantizer is not None:\n",
    "            quantizer.restore_real_value()\n",
    "\n",
    "            \n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('{phase} - Epoch: [{0}][{1}/{2}]\\t'\n",
    "                         'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                         'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                         'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                         'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                             epoch, i, len(data_loader),\n",
    "                             phase='TRAINING' if training else 'EVALUATING',\n",
    "                             batch_time=batch_time,\n",
    "                             data_time=data_time, top1=top1, top5=top5))\n",
    "\n",
    "    print('Top1: ', top1.avg)\n",
    "    return top1.avg, top5.avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy only clip_val from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.2.clip_val\n",
      "features.1.conv.0.2.clip_val\n",
      "features.1.conv.3.clip_val\n",
      "features.2.conv.0.2.clip_val\n",
      "features.2.conv.1.2.clip_val\n",
      "features.2.conv.4.clip_val\n",
      "features.3.finalFakeQuant.clip_val\n",
      "features.3.conv.0.2.clip_val\n",
      "features.3.conv.1.2.clip_val\n",
      "features.3.conv.4.clip_val\n",
      "features.4.conv.0.2.clip_val\n",
      "features.4.conv.1.2.clip_val\n",
      "features.4.conv.4.clip_val\n",
      "features.5.finalFakeQuant.clip_val\n",
      "features.5.conv.0.2.clip_val\n",
      "features.5.conv.1.2.clip_val\n",
      "features.5.conv.4.clip_val\n",
      "features.6.finalFakeQuant.clip_val\n",
      "features.6.conv.0.2.clip_val\n",
      "features.6.conv.1.2.clip_val\n",
      "features.6.conv.4.clip_val\n",
      "features.7.conv.0.2.clip_val\n",
      "features.7.conv.1.2.clip_val\n",
      "features.7.conv.4.clip_val\n",
      "features.8.finalFakeQuant.clip_val\n",
      "features.8.conv.0.2.clip_val\n",
      "features.8.conv.1.2.clip_val\n",
      "features.8.conv.4.clip_val\n",
      "features.9.finalFakeQuant.clip_val\n",
      "features.9.conv.0.2.clip_val\n",
      "features.9.conv.1.2.clip_val\n",
      "features.9.conv.4.clip_val\n",
      "features.10.finalFakeQuant.clip_val\n",
      "features.10.conv.0.2.clip_val\n",
      "features.10.conv.1.2.clip_val\n",
      "features.10.conv.4.clip_val\n",
      "features.11.conv.0.2.clip_val\n",
      "features.11.conv.1.2.clip_val\n",
      "features.11.conv.4.clip_val\n",
      "features.12.finalFakeQuant.clip_val\n",
      "features.12.conv.0.2.clip_val\n",
      "features.12.conv.1.2.clip_val\n",
      "features.12.conv.4.clip_val\n",
      "features.13.finalFakeQuant.clip_val\n",
      "features.13.conv.0.2.clip_val\n",
      "features.13.conv.1.2.clip_val\n",
      "features.13.conv.4.clip_val\n",
      "features.14.conv.0.2.clip_val\n",
      "features.14.conv.1.2.clip_val\n",
      "features.14.conv.4.clip_val\n",
      "features.15.finalFakeQuant.clip_val\n",
      "features.15.conv.0.2.clip_val\n",
      "features.15.conv.1.2.clip_val\n",
      "features.15.conv.4.clip_val\n",
      "features.16.finalFakeQuant.clip_val\n",
      "features.16.conv.0.2.clip_val\n",
      "features.16.conv.1.2.clip_val\n",
      "features.16.conv.4.clip_val\n",
      "features.17.conv.0.2.clip_val\n",
      "features.17.conv.1.2.clip_val\n",
      "features.17.conv.4.clip_val\n",
      "features.18.2.clip_val\n"
     ]
    }
   ],
   "source": [
    "new_state_dict = {}\n",
    "for item in state_dict.keys():\n",
    "    if 'clip' in item:\n",
    "        i = item.replace('module.','')\n",
    "        print(i)\n",
    "        new_state_dict[i] = state_dict[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=['features.0.0.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.weight', 'features.0.1.running_var', 'features.1.conv.0.0.weight', 'features.1.conv.0.1.bias', 'features.1.conv.0.1.running_mean', 'features.1.conv.0.1.weight', 'features.1.conv.0.1.running_var', 'features.1.conv.1.weight', 'features.1.conv.2.bias', 'features.1.conv.2.running_mean', 'features.1.conv.2.weight', 'features.1.conv.2.running_var', 'features.2.conv.0.0.weight', 'features.2.conv.0.1.bias', 'features.2.conv.0.1.running_mean', 'features.2.conv.0.1.weight', 'features.2.conv.0.1.running_var', 'features.2.conv.1.0.weight', 'features.2.conv.1.1.bias', 'features.2.conv.1.1.running_mean', 'features.2.conv.1.1.weight', 'features.2.conv.1.1.running_var', 'features.2.conv.2.weight', 'features.2.conv.3.bias', 'features.2.conv.3.running_mean', 'features.2.conv.3.weight', 'features.2.conv.3.running_var', 'features.3.conv.0.0.weight', 'features.3.conv.0.1.bias', 'features.3.conv.0.1.running_mean', 'features.3.conv.0.1.weight', 'features.3.conv.0.1.running_var', 'features.3.conv.1.0.weight', 'features.3.conv.1.1.bias', 'features.3.conv.1.1.running_mean', 'features.3.conv.1.1.weight', 'features.3.conv.1.1.running_var', 'features.3.conv.2.weight', 'features.3.conv.3.bias', 'features.3.conv.3.running_mean', 'features.3.conv.3.weight', 'features.3.conv.3.running_var', 'features.4.conv.0.0.weight', 'features.4.conv.0.1.bias', 'features.4.conv.0.1.running_mean', 'features.4.conv.0.1.weight', 'features.4.conv.0.1.running_var', 'features.4.conv.1.0.weight', 'features.4.conv.1.1.bias', 'features.4.conv.1.1.running_mean', 'features.4.conv.1.1.weight', 'features.4.conv.1.1.running_var', 'features.4.conv.2.weight', 'features.4.conv.3.bias', 'features.4.conv.3.running_mean', 'features.4.conv.3.weight', 'features.4.conv.3.running_var', 'features.5.conv.0.0.weight', 'features.5.conv.0.1.bias', 'features.5.conv.0.1.running_mean', 'features.5.conv.0.1.weight', 'features.5.conv.0.1.running_var', 'features.5.conv.1.0.weight', 'features.5.conv.1.1.bias', 'features.5.conv.1.1.running_mean', 'features.5.conv.1.1.weight', 'features.5.conv.1.1.running_var', 'features.5.conv.2.weight', 'features.5.conv.3.bias', 'features.5.conv.3.running_mean', 'features.5.conv.3.weight', 'features.5.conv.3.running_var', 'features.6.conv.0.0.weight', 'features.6.conv.0.1.bias', 'features.6.conv.0.1.running_mean', 'features.6.conv.0.1.weight', 'features.6.conv.0.1.running_var', 'features.6.conv.1.0.weight', 'features.6.conv.1.1.bias', 'features.6.conv.1.1.running_mean', 'features.6.conv.1.1.weight', 'features.6.conv.1.1.running_var', 'features.6.conv.2.weight', 'features.6.conv.3.bias', 'features.6.conv.3.running_mean', 'features.6.conv.3.weight', 'features.6.conv.3.running_var', 'features.7.conv.0.0.weight', 'features.7.conv.0.1.bias', 'features.7.conv.0.1.running_mean', 'features.7.conv.0.1.weight', 'features.7.conv.0.1.running_var', 'features.7.conv.1.0.weight', 'features.7.conv.1.1.bias', 'features.7.conv.1.1.running_mean', 'features.7.conv.1.1.weight', 'features.7.conv.1.1.running_var', 'features.7.conv.2.weight', 'features.7.conv.3.bias', 'features.7.conv.3.running_mean', 'features.7.conv.3.weight', 'features.7.conv.3.running_var', 'features.8.conv.0.0.weight', 'features.8.conv.0.1.bias', 'features.8.conv.0.1.running_mean', 'features.8.conv.0.1.weight', 'features.8.conv.0.1.running_var', 'features.8.conv.1.0.weight', 'features.8.conv.1.1.bias', 'features.8.conv.1.1.running_mean', 'features.8.conv.1.1.weight', 'features.8.conv.1.1.running_var', 'features.8.conv.2.weight', 'features.8.conv.3.bias', 'features.8.conv.3.running_mean', 'features.8.conv.3.weight', 'features.8.conv.3.running_var', 'features.9.conv.0.0.weight', 'features.9.conv.0.1.bias', 'features.9.conv.0.1.running_mean', 'features.9.conv.0.1.weight', 'features.9.conv.0.1.running_var', 'features.9.conv.1.0.weight', 'features.9.conv.1.1.bias', 'features.9.conv.1.1.running_mean', 'features.9.conv.1.1.weight', 'features.9.conv.1.1.running_var', 'features.9.conv.2.weight', 'features.9.conv.3.bias', 'features.9.conv.3.running_mean', 'features.9.conv.3.weight', 'features.9.conv.3.running_var', 'features.10.conv.0.0.weight', 'features.10.conv.0.1.bias', 'features.10.conv.0.1.running_mean', 'features.10.conv.0.1.weight', 'features.10.conv.0.1.running_var', 'features.10.conv.1.0.weight', 'features.10.conv.1.1.bias', 'features.10.conv.1.1.running_mean', 'features.10.conv.1.1.weight', 'features.10.conv.1.1.running_var', 'features.10.conv.2.weight', 'features.10.conv.3.bias', 'features.10.conv.3.running_mean', 'features.10.conv.3.weight', 'features.10.conv.3.running_var', 'features.11.conv.0.0.weight', 'features.11.conv.0.1.bias', 'features.11.conv.0.1.running_mean', 'features.11.conv.0.1.weight', 'features.11.conv.0.1.running_var', 'features.11.conv.1.0.weight', 'features.11.conv.1.1.bias', 'features.11.conv.1.1.running_mean', 'features.11.conv.1.1.weight', 'features.11.conv.1.1.running_var', 'features.11.conv.2.weight', 'features.11.conv.3.bias', 'features.11.conv.3.running_mean', 'features.11.conv.3.weight', 'features.11.conv.3.running_var', 'features.12.conv.0.0.weight', 'features.12.conv.0.1.bias', 'features.12.conv.0.1.running_mean', 'features.12.conv.0.1.weight', 'features.12.conv.0.1.running_var', 'features.12.conv.1.0.weight', 'features.12.conv.1.1.bias', 'features.12.conv.1.1.running_mean', 'features.12.conv.1.1.weight', 'features.12.conv.1.1.running_var', 'features.12.conv.2.weight', 'features.12.conv.3.bias', 'features.12.conv.3.running_mean', 'features.12.conv.3.weight', 'features.12.conv.3.running_var', 'features.13.conv.0.0.weight', 'features.13.conv.0.1.bias', 'features.13.conv.0.1.running_mean', 'features.13.conv.0.1.weight', 'features.13.conv.0.1.running_var', 'features.13.conv.1.0.weight', 'features.13.conv.1.1.bias', 'features.13.conv.1.1.running_mean', 'features.13.conv.1.1.weight', 'features.13.conv.1.1.running_var', 'features.13.conv.2.weight', 'features.13.conv.3.bias', 'features.13.conv.3.running_mean', 'features.13.conv.3.weight', 'features.13.conv.3.running_var', 'features.14.conv.0.0.weight', 'features.14.conv.0.1.bias', 'features.14.conv.0.1.running_mean', 'features.14.conv.0.1.weight', 'features.14.conv.0.1.running_var', 'features.14.conv.1.0.weight', 'features.14.conv.1.1.bias', 'features.14.conv.1.1.running_mean', 'features.14.conv.1.1.weight', 'features.14.conv.1.1.running_var', 'features.14.conv.2.weight', 'features.14.conv.3.bias', 'features.14.conv.3.running_mean', 'features.14.conv.3.weight', 'features.14.conv.3.running_var', 'features.15.conv.0.0.weight', 'features.15.conv.0.1.bias', 'features.15.conv.0.1.running_mean', 'features.15.conv.0.1.weight', 'features.15.conv.0.1.running_var', 'features.15.conv.1.0.weight', 'features.15.conv.1.1.bias', 'features.15.conv.1.1.running_mean', 'features.15.conv.1.1.weight', 'features.15.conv.1.1.running_var', 'features.15.conv.2.weight', 'features.15.conv.3.bias', 'features.15.conv.3.running_mean', 'features.15.conv.3.weight', 'features.15.conv.3.running_var', 'features.16.conv.0.0.weight', 'features.16.conv.0.1.bias', 'features.16.conv.0.1.running_mean', 'features.16.conv.0.1.weight', 'features.16.conv.0.1.running_var', 'features.16.conv.1.0.weight', 'features.16.conv.1.1.bias', 'features.16.conv.1.1.running_mean', 'features.16.conv.1.1.weight', 'features.16.conv.1.1.running_var', 'features.16.conv.2.weight', 'features.16.conv.3.bias', 'features.16.conv.3.running_mean', 'features.16.conv.3.weight', 'features.16.conv.3.running_var', 'features.17.conv.0.0.weight', 'features.17.conv.0.1.bias', 'features.17.conv.0.1.running_mean', 'features.17.conv.0.1.weight', 'features.17.conv.0.1.running_var', 'features.17.conv.1.0.weight', 'features.17.conv.1.1.bias', 'features.17.conv.1.1.running_mean', 'features.17.conv.1.1.weight', 'features.17.conv.1.1.running_var', 'features.17.conv.2.weight', 'features.17.conv.3.bias', 'features.17.conv.3.running_mean', 'features.17.conv.3.weight', 'features.17.conv.3.running_var', 'features.18.0.weight', 'features.18.1.bias', 'features.18.1.running_mean', 'features.18.1.weight', 'features.18.1.running_var', 'classifier.1.bias', 'classifier.1.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LearnedClippedLinearQuantization(num_bits=4, clip_val=Parameter containing:\n",
       "      tensor([2.7349], requires_grad=True), inplace)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=4, clip_val=Parameter containing:\n",
       "          tensor([4.2259], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([2.4454], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=2, clip_val=Parameter containing:\n",
       "          tensor([3.5854], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=4, clip_val=Parameter containing:\n",
       "          tensor([3.3601], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([2.6797], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([3.1758], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=4, clip_val=Parameter containing:\n",
       "          tensor([1.9695], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=2, clip_val=Parameter containing:\n",
       "          tensor([2.7713], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([2.2031], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=2, clip_val=Parameter containing:\n",
       "          tensor([2.6114], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.1039], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([2.2227], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([2.2822], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.0970], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.2883], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.5154], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([2.5390], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.9423], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.1724], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.4239], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.1573], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.6004], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.6697], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.7763], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.7142], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.0013], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.3911], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.8406], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.7170], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.0929], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([0.9593], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.9598], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.6265], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.0080], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.3570], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.9330], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.7000], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.4853], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.6468], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.9117], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.3749], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.1005], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.9797], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.9606], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.1398], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.4788], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.0503], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.3764], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.5105], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([1.8491], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.2366], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.1965], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.2863], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (finalFakeQuant): LearnedClippedSymLinearQuantizationADD(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([2.7847], requires_grad=True))\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([1.2615], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.4828], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([2.1198], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([0.7363], requires_grad=True), inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "          tensor([2.0610], requires_grad=True), inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LearnedClippedSymLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "        tensor([1.4083], requires_grad=True))\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LearnedClippedLinearQuantization(num_bits=8, clip_val=Parameter containing:\n",
       "      tensor([4.7197], requires_grad=True), inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute S parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned 0.18232577641805012 1\n",
      "Learned 0.28172709147135416 2\n",
      "Sym 0.019179263769411575 3\n",
      "Learned 1.1951462427775066 4\n",
      "Learned 0.22400767008463543 5\n",
      "Sym 0.0210171755622415 6\n",
      "SymdADD 0.024908028396905636 7\n",
      "Learned 0.13129773139953613 8\n",
      "Learned 0.923762321472168 9\n",
      "Sym 0.0172790901333678 10\n",
      "Learned 0.870475689570109 11\n",
      "Learned 0.008250396391924689 12\n",
      "Sym 0.01743301503798541 13\n",
      "SymdADD 0.017899438446643306 14\n",
      "Learned 0.004301923864028033 15\n",
      "Learned 0.00505209202859916 16\n",
      "Sym 0.011885747722550934 17\n",
      "SymdADD 0.019913520065008426 18\n",
      "Learned 0.0036952635821174175 19\n",
      "Learned 0.004597809735466452 20\n",
      "Sym 0.011167555229336608 21\n",
      "Learned 0.004538429017160453 22\n",
      "Learned 0.00627599463743322 23\n",
      "Sym 0.013095423754523782 24\n",
      "SymdADD 0.013931683933033663 25\n",
      "Learned 0.0028008402562608907 26\n",
      "Learned 0.003926560458014993 27\n",
      "Sym 0.010910812078737744 28\n",
      "SymdADD 0.01443641699996649 29\n",
      "Learned 0.0028118154581855325 30\n",
      "Learned 0.004286027422138289 31\n",
      "Sym 0.0075239859375299195 32\n",
      "SymdADD 0.015370744817397173 33\n",
      "Learned 0.002456952076332242 34\n",
      "Learned 0.007874408422731885 35\n",
      "Sym 0.010643331677305932 36\n",
      "Learned 0.0036586836272594976 37\n",
      "Learned 0.006666722484663421 38\n",
      "Sym 0.011649050432093003 39\n",
      "SymdADD 0.012915984322043026 40\n",
      "Learned 0.003575307247685451 41\n",
      "Learned 0.005391867488038306 42\n",
      "Sym 0.008631174237120386 43\n",
      "SymdADD 0.01552744566225538 44\n",
      "Learned 0.0037669249609404917 45\n",
      "Learned 0.008391568239997415 46\n",
      "Sym 0.011598639394722733 47\n",
      "Learned 0.004118756686939912 48\n",
      "Learned 0.009319317574594536 49\n",
      "Sym 0.011846769557279698 50\n",
      "SymdADD 0.014502926433787627 51\n",
      "Learned 0.004849592377157773 52\n",
      "Learned 0.008613869723151712 53\n",
      "Sym 0.010088589612175437 54\n",
      "SymdADD 0.021840996835746015 55\n",
      "Learned 0.004947066774555281 56\n",
      "Learned 0.00973638553245395 57\n",
      "Sym 0.0166260326609892 58\n",
      "Learned 0.0028874586610233084 59\n",
      "Learned 0.008082180397183288 60\n",
      "Sym 0.01104585049199123 61\n",
      "Learned 0.018508735357546338 62\n"
     ]
    }
   ],
   "source": [
    "S_ai_l = [2/255]\n",
    "Act_bits = []\n",
    "for item in model.modules():\n",
    "    if type(item) is models.linear_quantized_modules.LearnedClippedLinearQuantization:\n",
    "        a_bits = item.num_bits\n",
    "        Act_bits.append(a_bits)\n",
    "        n_levels_a = (2**a_bits)-1\n",
    "        a_max = item.clip_val.data.item()\n",
    "        S_a = a_max / n_levels_a\n",
    "        print('Learned',S_a,len(S_ai_l))\n",
    "        S_ai_l.append(S_a)\n",
    "    elif type(item) is models.linear_quantized_modules.LearnedClippedSymLinearQuantization:\n",
    "        a_bits = item.num_bits\n",
    "        Act_bits.append(a_bits)\n",
    "        n_levels_a = (2**a_bits)-1\n",
    "        a_max = item.clip_val.data.item()\n",
    "        S_a = 2* a_max / n_levels_a\n",
    "        print('Sym',S_a,len(S_ai_l))\n",
    "        S_ai_l.append(S_a)\n",
    "    elif type(item) is models.linear_quantized_modules.LearnedClippedSymLinearQuantizationADD:\n",
    "        a_bits = item.num_bits\n",
    "        #Act_bits.append(a_bits)\n",
    "        n_levels_a = (2**a_bits)-1\n",
    "        a_max = item.clip_val.data.item()\n",
    "        S_a = 2* a_max / n_levels_a\n",
    "        print('SymdADD',S_a,len(S_ai_l))\n",
    "        S_ai_l.append(S_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The array below specify the S_ai and S_ao parameter of any given conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ai_vector = [0,1,2,3,4,5,6,8,9,7,11,12,13,15,16,14,19,20,18,22,23,24,26,27,25,30,31,29,34,35,33,37,38,39,41,42,40,45,46,44,48,49,50,52,53,51,56,57,55,59,60,61,62]\n",
    "S_ao_vector = [1,2,3,4,5,6,8,9,10,11,12,13,15,16,17,19,20,21,22,23,24,26,27,28,30,31,32,34,35,36,37,38,39,41,42,43,45,46,47,48,49,50,52,53,54,56,57,58,59,60,61,62]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = [6,13,14,24,25,29,39,40,50,51]\n",
    "S2 = [10,17,21,28,32,36,43,47,54,58]\n",
    "S3 = [7,14,18,25,29,33,40,44,51,55]\n",
    "nRes = len(S1)\n",
    "\n",
    "S1_ai = [S_ai_l[S1[i]] for i in range(nRes)]\n",
    "S2_ai = [S_ai_l[S2[i]] for i in range(nRes)]\n",
    "S3_ai = [S_ai_l[S3[i]] for i in range(nRes)]\n",
    "scaleRes = [ S1_ai[i]/S2_ai[i] for i in range(nRes)]\n",
    "scaleRes2 =[ S2_ai[i]/S3_ai[i] for i in range(nRes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2163357792581364,\n",
       " 1.4667158890567393,\n",
       " 1.602807246443911,\n",
       " 1.200224480086433,\n",
       " 1.8516360940471603,\n",
       " 1.356381388616151,\n",
       " 1.3496483922191647,\n",
       " 1.1135775397862333,\n",
       " 1.1742741069556837,\n",
       " 0.8723022942097809]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vector = []\n",
    "bias_vector = []\n",
    "M0_vector = []\n",
    "N0_vector = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Quantized values and M,N parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00784313725490196 0.18232577641805012\n",
      "0.18232577641805012 0.28172709147135416\n",
      "0.28172709147135416 0.019179263769411575\n",
      "0.019179263769411575 1.1951462427775066\n",
      "1.1951462427775066 0.22400767008463543\n",
      "0.22400767008463543 0.0210171755622415\n",
      "0.0210171755622415 0.13129773139953613\n",
      "0.13129773139953613 0.923762321472168\n",
      "0.923762321472168 0.0172790901333678\n",
      "0.024908028396905636 0.870475689570109\n",
      "0.870475689570109 0.008250396391924689\n",
      "0.008250396391924689 0.01743301503798541\n",
      "0.01743301503798541 0.004301923864028033\n",
      "0.004301923864028033 0.00505209202859916\n",
      "0.00505209202859916 0.011885747722550934\n",
      "0.017899438446643306 0.0036952635821174175\n",
      "0.0036952635821174175 0.004597809735466452\n",
      "0.004597809735466452 0.011167555229336608\n",
      "0.019913520065008426 0.004538429017160453\n",
      "0.004538429017160453 0.00627599463743322\n",
      "0.00627599463743322 0.013095423754523782\n",
      "0.013095423754523782 0.0028008402562608907\n",
      "0.0028008402562608907 0.003926560458014993\n",
      "0.003926560458014993 0.010910812078737744\n",
      "0.013931683933033663 0.0028118154581855325\n",
      "0.0028118154581855325 0.004286027422138289\n",
      "0.004286027422138289 0.0075239859375299195\n",
      "0.01443641699996649 0.002456952076332242\n",
      "0.002456952076332242 0.007874408422731885\n",
      "0.007874408422731885 0.010643331677305932\n",
      "0.015370744817397173 0.0036586836272594976\n",
      "0.0036586836272594976 0.006666722484663421\n",
      "0.006666722484663421 0.011649050432093003\n",
      "0.011649050432093003 0.003575307247685451\n",
      "0.003575307247685451 0.005391867488038306\n",
      "0.005391867488038306 0.008631174237120386\n",
      "0.012915984322043026 0.0037669249609404917\n",
      "0.0037669249609404917 0.008391568239997415\n",
      "0.008391568239997415 0.011598639394722733\n",
      "0.01552744566225538 0.004118756686939912\n",
      "0.004118756686939912 0.009319317574594536\n",
      "0.009319317574594536 0.011846769557279698\n",
      "0.011846769557279698 0.004849592377157773\n",
      "0.004849592377157773 0.008613869723151712\n",
      "0.008613869723151712 0.010088589612175437\n",
      "0.014502926433787627 0.004947066774555281\n",
      "0.004947066774555281 0.00973638553245395\n",
      "0.00973638553245395 0.0166260326609892\n",
      "0.021840996835746015 0.0028874586610233084\n",
      "0.0028874586610233084 0.008082180397183288\n",
      "0.008082180397183288 0.01104585049199123\n",
      "0.01104585049199123 0.018508735357546338\n",
      "0.018508735357546338\n"
     ]
    }
   ],
   "source": [
    "###################################          PARAMS BITS         #############################################\n",
    "BIAS_BITS = 32  #INT32\n",
    "M0_BITS = 32\n",
    "N0_BITS = 8\n",
    "BIAS_CH_BITS = 16\n",
    "M0_BITS_LAST = 8\n",
    "BIAS_FIXED_BITS = 0\n",
    "    \n",
    "for i_l,layer in enumerate(quantizer_load.param_to_quantize):\n",
    "    quant_type = layer['quant_type']\n",
    "    w_bits = layer['w_bits']\n",
    "    conv_layer = layer['conv']\n",
    "    bias_bits = layer['bias_bits']\n",
    "\n",
    "    if quant_type == 'PerChannelsAsymMinMax':\n",
    "        weight_org = conv_layer.weight.data.clone()\n",
    "        w_min_tensor, w_max_tensor = 0,0\n",
    "\n",
    "        weight_tensor, bias_tensor, w_min_mat, w_max_mat = quantizer._quant_PerChannelsAsymMinMax( \\\n",
    "                    conv_layer, layer['batch_norm'], layer['fold_type'], w_bits, i_l, w_min_tensor, \\\n",
    "                    w_max_tensor, training=False, get_quantized=False )\n",
    "        \n",
    "        conv_layer.weight.data.copy_(weight_org)\n",
    "    else:\n",
    "        print('Not recognized quantization scheme!')\n",
    "        exit() \n",
    "\n",
    "###################################          LEAF layers          #############################################\n",
    "    if type(conv_layer) is nn.Linear:\n",
    "        n_levels_w = (2**w_bits)-1\n",
    "\n",
    "        if quant_type == 'PerChannelsAsymMinMax':    # per channel quantization\n",
    "\n",
    "            weight_quant_tensor = weight_tensor.clone()\n",
    "            if bias_tensor is not False:\n",
    "                bias_quant_tensor = bias_tensor\n",
    "            else:\n",
    "                bias_quant_tensor = False\n",
    "\n",
    "            S_a_i = S_ai_l[S_ai_vector[i_l]]\n",
    "            print(S_a_i)\n",
    "\n",
    "            for v in range(weight_tensor.size(0)) :\n",
    "                #w_min_value,w_max_value= layer['w_min_thr'].data[v], layer['w_max_thr'].data[v]\n",
    "                w_min_value,w_max_value= weight_tensor[v].min(), weight_tensor[v].max()\n",
    "                range_w = w_max_value-w_min_value\n",
    "                if range_w == 0:\n",
    "                    range_w = 1\n",
    "                S_w = (range_w) / n_levels_w\n",
    "\n",
    "                weight_quant_tensor[v] = weight_tensor[v].div(S_w).round()\n",
    "\n",
    "                if bias_tensor is not False:\n",
    "                    bias_quant_tensor[v] = bias_tensor[v].div( S_w * S_a_i ).mul(2**BIAS_FIXED_BITS).round().clamp(-2**(BIAS_BITS-1), 2**(BIAS_BITS-1)-1 ).div(2**BIAS_FIXED_BITS)\n",
    "\n",
    "            w_max_value , _ = weight_tensor.reshape(weight_tensor.size(0), -1).max(1)\n",
    "            w_min_value , _ = weight_tensor.reshape(weight_tensor.size(0), -1).min(1)\n",
    "\n",
    "            range_w = w_max_value-w_min_value\n",
    "            range_w.masked_fill_(range_w.eq(0), 1)\n",
    "            S_w = (range_w) / n_levels_w\n",
    "            M0, n_exp = quantizer._get_m0_nexp_vect(S_w)\n",
    "            M0 = M0.mul(2**(M0_BITS_LAST-1)).round().clamp(-2**(M0_BITS_LAST-1),2**(M0_BITS_LAST-1)-1).div(2**(M0_BITS_LAST-1))   #assume Q.1.31\n",
    "            n_exp = n_exp.clamp(-2**(N0_BITS-1),2**(N0_BITS-1)-1  )\n",
    "            layer['quant_act'].M_ZERO = M0\n",
    "            layer['quant_act'].N_ZERO = 2**n_exp    \n",
    "\n",
    "            weight_vector.append(weight_quant_tensor)\n",
    "            bias_vector.append(bias_quant_tensor)\n",
    "            M0_vector.append(M0)\n",
    "            N0_vector.append(2**n_exp)\n",
    "\n",
    "            layer['quant_conv'].weight.data.copy_( weight_quant_tensor )\n",
    "            if bias_quant_tensor is not False:\n",
    "                layer['quant_conv'].bias = nn.Parameter(bias_quant_tensor, requires_grad = False)\n",
    "\n",
    "\n",
    "\n",
    "###################################          OTHERS layers       #############################################\n",
    "    else:\n",
    "        S_a_i = S_ai_l[S_ai_vector[i_l]]\n",
    "        S_a_o = S_ai_l[S_ao_vector[i_l]]\n",
    "        print(S_a_i, S_a_o)\n",
    "\n",
    "        n_levels_w = (2**w_bits)-1\n",
    "\n",
    "        if quant_type == 'PerChannelsAsymMinMax':    # per channel quantization\n",
    "\n",
    "            if layer['fold_type'] == 'ICN':\n",
    "\n",
    "                batch_layer = layer['batch_norm']\n",
    "                gamma_over_sigma, mu_tensor, beta_tensor = quantizer._get_BN_scale_factors(batch_layer)\n",
    "                if bias_tensor is not False:\n",
    "                    bias_tensor = bias_tensor.add(-mu_tensor)\n",
    "                    print('hereeee')\n",
    "                else:\n",
    "                    bias_tensor = -mu_tensor.clone()\n",
    "\n",
    "                #w_min_value,w_max_value= layer['w_min_thr'].data, layer['w_max_thr'].data\n",
    "                w_max_value , _ = weight_tensor.reshape(weight_tensor.size(0), -1).max(1)\n",
    "                w_min_value , _ = weight_tensor.reshape(weight_tensor.size(0), -1).min(1)\n",
    "                range_w = w_max_value-w_min_value\n",
    "                range_w.masked_fill_(range_w.eq(0), 1)\n",
    "                S_w = (range_w) / n_levels_w\n",
    "                bias_tensor = bias_tensor.add(beta_tensor/gamma_over_sigma).div(S_a_i*S_w).mul(2**BIAS_FIXED_BITS).round().clamp(-2**(BIAS_BITS-1),2**(BIAS_BITS-1)-1).div(2**BIAS_FIXED_BITS)  #assume INT8\n",
    "                layer['quant_conv'].bias = nn.Parameter(bias_tensor, requires_grad = False)\n",
    "\n",
    "\n",
    "                weight_quant_tensor = weight_tensor.clone()\n",
    "                for v in range(weight_tensor.size(0)) :\n",
    "                    #w_min_value, w_max_value= layer['w_min_thr'].data[v], layer['w_max_thr'].data[v]\n",
    "                    w_min_value,w_max_value= weight_tensor[v].min(), weight_tensor[v].max()\n",
    "                    range_w = w_max_value-w_min_value\n",
    "                    if range_w == 0:\n",
    "                        range_w = 1\n",
    "                        print('hhhhh')\n",
    "\n",
    "                    S_w = range_w / n_levels_w\n",
    "                    weight_quant_tensor[v] = weight_tensor[v].div(S_w).round()\n",
    "                    gamma_over_sigma[v] = gamma_over_sigma[v].mul((S_a_i*S_w)/S_a_o)\n",
    "\n",
    "                weight_vector.append(weight_quant_tensor)\n",
    "                bias_vector.append(bias_tensor)\n",
    "                \n",
    "                #print('min:', weight_quant_tensor.min(),'max: ', weight_quant_tensor.max())\n",
    "                M0, n_exp = quantizer._get_m0_nexp_vect(gamma_over_sigma)\n",
    "                M0 = M0.mul(2**(M0_BITS-1)).round().clamp(-2**(M0_BITS-1),2**(M0_BITS-1)-1).div(2**(M0_BITS-1))   #assume Q.1.31\n",
    "                n_exp = n_exp.clamp(-2**(N0_BITS-1),2**(N0_BITS-1)-1  )\n",
    "                \n",
    "                M0_vector.append(M0)\n",
    "                N0_vector.append(2**n_exp)\n",
    "                #layer['quant_act'].M_ZERO = M0\n",
    "                #layer['quant_act'].N_ZERO = 2**n_exp                    \n",
    "                #layer['quant_act'].clip_val = nl_a_o\n",
    "                #layer['quant_conv'].weight.data.copy_( weight_quant_tensor )\n",
    "\n",
    "            else:\n",
    "                print('Not supported yet!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00784313725490196,\n",
       " 0.18232577641805012,\n",
       " 0.28172709147135416,\n",
       " 0.019179263769411575,\n",
       " 1.1951462427775066,\n",
       " 0.22400767008463543,\n",
       " 0.0210171755622415,\n",
       " 0.024908028396905636,\n",
       " 0.13129773139953613,\n",
       " 0.923762321472168,\n",
       " 0.0172790901333678,\n",
       " 0.870475689570109,\n",
       " 0.008250396391924689,\n",
       " 0.01743301503798541,\n",
       " 0.017899438446643306,\n",
       " 0.004301923864028033,\n",
       " 0.00505209202859916,\n",
       " 0.011885747722550934,\n",
       " 0.019913520065008426,\n",
       " 0.0036952635821174175,\n",
       " 0.004597809735466452,\n",
       " 0.011167555229336608,\n",
       " 0.004538429017160453,\n",
       " 0.00627599463743322,\n",
       " 0.013095423754523782,\n",
       " 0.013931683933033663,\n",
       " 0.0028008402562608907,\n",
       " 0.003926560458014993,\n",
       " 0.010910812078737744,\n",
       " 0.01443641699996649,\n",
       " 0.0028118154581855325,\n",
       " 0.004286027422138289,\n",
       " 0.0075239859375299195,\n",
       " 0.015370744817397173,\n",
       " 0.002456952076332242,\n",
       " 0.007874408422731885,\n",
       " 0.010643331677305932,\n",
       " 0.0036586836272594976,\n",
       " 0.006666722484663421,\n",
       " 0.011649050432093003,\n",
       " 0.012915984322043026,\n",
       " 0.003575307247685451,\n",
       " 0.005391867488038306,\n",
       " 0.008631174237120386,\n",
       " 0.01552744566225538,\n",
       " 0.0037669249609404917,\n",
       " 0.008391568239997415,\n",
       " 0.011598639394722733,\n",
       " 0.004118756686939912,\n",
       " 0.009319317574594536,\n",
       " 0.011846769557279698,\n",
       " 0.014502926433787627,\n",
       " 0.004849592377157773,\n",
       " 0.008613869723151712,\n",
       " 0.010088589612175437,\n",
       " 0.021840996835746015,\n",
       " 0.004947066774555281,\n",
       " 0.00973638553245395,\n",
       " 0.0166260326609892,\n",
       " 0.0028874586610233084,\n",
       " 0.008082180397183288,\n",
       " 0.01104585049199123,\n",
       " 0.018508735357546338]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_ai_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define integer-only mobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2Integer(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLUInteger(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "    )\n",
       "    (1): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[1,2], inplace)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLUInteger(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): ScaledClippedLinearQuantizationChannel(clip_val=1, inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (1): ScaledClippedLinearQuantizationChannelBias(clip_val=1, inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_int = models.mobilenetv2(activ_type='learned', act_bits=8,integer=True)\n",
    "mobilenet_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy quantized values into integer-only network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for item in mobilenet_int.modules():\n",
    "    if type(item) in [nn.Conv2d, nn.Linear]:\n",
    "        item.weight.data.copy_( weight_vector[c] )\n",
    "        item.bias = nn.Parameter(bias_vector[c] , requires_grad = False)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 4\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 4\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 2\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 4\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 4\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 2\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 2\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "******* <class 'models.imagenet.mobilenetv2.InvertedResidualInteger'>\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannel'> 8\n",
      "---- <class 'models.linear_quantized_modules.ScaledClippedLinearQuantizationChannelBias'>\n"
     ]
    }
   ],
   "source": [
    "Act_bits\n",
    "a = 0\n",
    "m = 0\n",
    "r = 0\n",
    "M0_vector\n",
    "N0_vector\n",
    "for i in mobilenet_int.modules():\n",
    "    if type(i) is models.imagenet.mobilenetv2.InvertedResidualInteger:\n",
    "        if i.use_res_connect:\n",
    "            print('*******',type(i))\n",
    "            i.scaleRes = scaleRes[r] #this is still FP\n",
    "            i.scaleRes2 =  scaleRes2[r] #this is still FP\n",
    "            r+=1\n",
    "    elif type(i) is models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannel:\n",
    "        print('----',type(i), Act_bits[a])\n",
    "        a_bits = Act_bits[a]\n",
    "        a +=1\n",
    "        i.clip_val= 2**a_bits -1\n",
    "        i.M_ZERO = M0_vector[m].cuda()\n",
    "        i.N_ZERO = N0_vector[m].cuda()\n",
    "        m+=1\n",
    "    elif type(i) is models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBiasSym:\n",
    "        print('----',type(i), Act_bits[a])\n",
    "        a_bits = Act_bits[a]\n",
    "        i.clip_val_low= -2**(a_bits-1)\n",
    "        i.clip_val_high=2**(a_bits-1) -1\n",
    "        a +=1 \n",
    "        i.M_ZERO = M0_vector[m].cuda()\n",
    "        i.N_ZERO = N0_vector[m].cuda()\n",
    "        m+=1            \n",
    "    elif type(i) is models.imagenet.mobilenetv2.ScaledClippedLinearQuantizationChannelBias:\n",
    "        print('----',type(i))\n",
    "        i.M_ZERO = M0_vector[m].cuda()\n",
    "        i.N_ZERO = N0_vector[m].cuda()\n",
    "        m+=1       \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2Integer(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLUInteger(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ScaledClippedLinearQuantizationChannel(clip_val=15, inplace)\n",
       "    )\n",
       "    (1): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=15, inplace)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=3, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=15, inplace)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=15, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=3, inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=3, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidualInteger(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLUInteger(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (1): ConvBNReLUInteger(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "          (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ScaledClippedLinearQuantizationChannelBiasSym(clip_val=[-128,127], inplace)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLUInteger(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ScaledClippedLinearQuantizationChannel(clip_val=255, inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (1): ScaledClippedLinearQuantizationChannelBias(clip_val=1, inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING - Epoch: [0][0/3125]\tTime 0.885 (0.885)\tData 0.787 (0.787)\tPrec@1 75.000 (75.000)\tPrec@5 81.250 (81.250)\n",
      "EVALUATING - Epoch: [0][100/3125]\tTime 0.021 (0.057)\tData 0.000 (0.031)\tPrec@1 43.750 (71.225)\tPrec@5 75.000 (88.614)\n",
      "EVALUATING - Epoch: [0][200/3125]\tTime 0.033 (0.041)\tData 0.000 (0.016)\tPrec@1 50.000 (62.065)\tPrec@5 68.750 (83.364)\n",
      "EVALUATING - Epoch: [0][300/3125]\tTime 0.031 (0.057)\tData 0.000 (0.032)\tPrec@1 87.500 (64.369)\tPrec@5 93.750 (84.738)\n",
      "EVALUATING - Epoch: [0][400/3125]\tTime 1.030 (0.076)\tData 1.000 (0.050)\tPrec@1 75.000 (63.622)\tPrec@5 100.000 (84.133)\n",
      "EVALUATING - Epoch: [0][500/3125]\tTime 0.613 (0.089)\tData 0.586 (0.064)\tPrec@1 81.250 (65.095)\tPrec@5 93.750 (85.055)\n",
      "EVALUATING - Epoch: [0][600/3125]\tTime 0.021 (0.107)\tData 0.000 (0.082)\tPrec@1 62.500 (63.467)\tPrec@5 87.500 (84.599)\n",
      "EVALUATING - Epoch: [0][700/3125]\tTime 0.022 (0.116)\tData 0.000 (0.091)\tPrec@1 43.750 (62.643)\tPrec@5 87.500 (84.362)\n",
      "EVALUATING - Epoch: [0][800/3125]\tTime 0.413 (0.118)\tData 0.384 (0.093)\tPrec@1 43.750 (61.876)\tPrec@5 81.250 (84.277)\n",
      "EVALUATING - Epoch: [0][900/3125]\tTime 0.022 (0.120)\tData 0.000 (0.095)\tPrec@1 56.250 (61.654)\tPrec@5 93.750 (84.261)\n",
      "EVALUATING - Epoch: [0][1000/3125]\tTime 0.021 (0.117)\tData 0.000 (0.092)\tPrec@1 100.000 (61.932)\tPrec@5 100.000 (84.590)\n",
      "EVALUATING - Epoch: [0][1100/3125]\tTime 0.023 (0.122)\tData 0.000 (0.097)\tPrec@1 87.500 (62.721)\tPrec@5 100.000 (84.911)\n",
      "EVALUATING - Epoch: [0][1200/3125]\tTime 0.023 (0.124)\tData 0.000 (0.100)\tPrec@1 62.500 (62.448)\tPrec@5 81.250 (84.784)\n",
      "EVALUATING - Epoch: [0][1300/3125]\tTime 0.022 (0.126)\tData 0.000 (0.101)\tPrec@1 68.750 (61.976)\tPrec@5 87.500 (84.397)\n",
      "EVALUATING - Epoch: [0][1400/3125]\tTime 0.022 (0.128)\tData 0.000 (0.103)\tPrec@1 50.000 (61.193)\tPrec@5 81.250 (83.811)\n",
      "EVALUATING - Epoch: [0][1500/3125]\tTime 0.025 (0.128)\tData 0.000 (0.103)\tPrec@1 56.250 (60.601)\tPrec@5 75.000 (83.290)\n",
      "EVALUATING - Epoch: [0][1600/3125]\tTime 0.027 (0.131)\tData 0.000 (0.107)\tPrec@1 68.750 (59.857)\tPrec@5 75.000 (82.691)\n",
      "EVALUATING - Epoch: [0][1700/3125]\tTime 0.022 (0.132)\tData 0.000 (0.108)\tPrec@1 56.250 (59.263)\tPrec@5 87.500 (82.294)\n",
      "EVALUATING - Epoch: [0][1800/3125]\tTime 0.023 (0.132)\tData 0.000 (0.108)\tPrec@1 87.500 (59.391)\tPrec@5 93.750 (82.159)\n",
      "EVALUATING - Epoch: [0][1900/3125]\tTime 0.026 (0.130)\tData 0.000 (0.106)\tPrec@1 75.000 (59.123)\tPrec@5 87.500 (81.858)\n",
      "EVALUATING - Epoch: [0][2000/3125]\tTime 0.022 (0.126)\tData 0.000 (0.102)\tPrec@1 87.500 (58.689)\tPrec@5 100.000 (81.534)\n",
      "EVALUATING - Epoch: [0][2100/3125]\tTime 0.024 (0.124)\tData 0.000 (0.099)\tPrec@1 68.750 (58.362)\tPrec@5 87.500 (81.354)\n",
      "EVALUATING - Epoch: [0][2200/3125]\tTime 0.022 (0.121)\tData 0.000 (0.097)\tPrec@1 56.250 (58.011)\tPrec@5 75.000 (80.929)\n",
      "EVALUATING - Epoch: [0][2300/3125]\tTime 0.026 (0.119)\tData 0.000 (0.094)\tPrec@1 75.000 (57.752)\tPrec@5 75.000 (80.685)\n",
      "EVALUATING - Epoch: [0][2400/3125]\tTime 0.023 (0.117)\tData 0.000 (0.093)\tPrec@1 62.500 (57.447)\tPrec@5 81.250 (80.399)\n",
      "EVALUATING - Epoch: [0][2500/3125]\tTime 0.021 (0.115)\tData 0.000 (0.090)\tPrec@1 87.500 (57.182)\tPrec@5 100.000 (80.100)\n",
      "EVALUATING - Epoch: [0][2600/3125]\tTime 0.025 (0.113)\tData 0.000 (0.089)\tPrec@1 87.500 (56.961)\tPrec@5 93.750 (79.981)\n",
      "EVALUATING - Epoch: [0][2700/3125]\tTime 0.022 (0.111)\tData 0.000 (0.086)\tPrec@1 50.000 (56.509)\tPrec@5 93.750 (79.616)\n",
      "EVALUATING - Epoch: [0][2800/3125]\tTime 0.026 (0.109)\tData 0.000 (0.084)\tPrec@1 75.000 (56.402)\tPrec@5 87.500 (79.483)\n",
      "EVALUATING - Epoch: [0][2900/3125]\tTime 0.022 (0.106)\tData 0.000 (0.082)\tPrec@1 37.500 (56.254)\tPrec@5 81.250 (79.427)\n",
      "EVALUATING - Epoch: [0][3000/3125]\tTime 0.026 (0.104)\tData 0.000 (0.080)\tPrec@1 31.250 (56.506)\tPrec@5 68.750 (79.615)\n",
      "EVALUATING - Epoch: [0][3100/3125]\tTime 0.022 (0.102)\tData 0.000 (0.078)\tPrec@1 87.500 (56.476)\tPrec@5 100.000 (79.607)\n",
      "Top1:  56.546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56.546, 79.628)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_int.eval()\n",
    "forward(val_loader, mobilenet_int.cuda(), quantizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[  48.,  -16.,   54.],\n",
       "           [ 119.,  -92.,   25.],\n",
       "           [  38., -136.,  -54.]],\n",
       " \n",
       "          [[  29.,  -22.,   55.],\n",
       "           [  73., -119.,   -8.],\n",
       "           [  41., -120.,  -29.]],\n",
       " \n",
       "          [[ -92.,  -73.,  -36.],\n",
       "           [ -41., -106.,  -55.],\n",
       "           [ -96., -122.,  -88.]]],\n",
       " \n",
       " \n",
       "         [[[ -12.,    7.,   17.],\n",
       "           [  50.,   65.,    8.],\n",
       "           [ -33.,  -68.,  -19.]],\n",
       " \n",
       "          [[ -11.,   15.,    9.],\n",
       "           [  74.,  121.,    9.],\n",
       "           [ -68., -134.,  -29.]],\n",
       " \n",
       "          [[  -3.,    8.,   20.],\n",
       "           [  22.,   28.,    7.],\n",
       "           [ -13.,  -42.,  -12.]]],\n",
       " \n",
       " \n",
       "         [[[ -17.,   19.,    7.],\n",
       "           [ -47.,   78.,  -27.],\n",
       "           [ -72.,   93.,  -30.]],\n",
       " \n",
       "          [[ -17.,   25.,    4.],\n",
       "           [ -89.,  135.,  -49.],\n",
       "           [-110.,  145.,  -47.]],\n",
       " \n",
       "          [[  -5.,    4.,    7.],\n",
       "           [ -22.,   39.,  -17.],\n",
       "           [ -26.,   41.,  -20.]]],\n",
       " \n",
       " \n",
       "         [[[  24.,  -15.,   -1.],\n",
       "           [  31.,   31.,  -54.],\n",
       "           [  17.,   63.,  -64.]],\n",
       " \n",
       "          [[  17.,  -29.,   -6.],\n",
       "           [  22.,   79., -121.],\n",
       "           [  12.,  116., -139.]],\n",
       " \n",
       "          [[  15.,  -12.,  -11.],\n",
       "           [  20.,   14.,   -5.],\n",
       "           [   7.,   31.,   -9.]]],\n",
       " \n",
       " \n",
       "         [[[ -20.,   12.,   16.],\n",
       "           [  -4.,  -47.,  -30.],\n",
       "           [  52.,  -37., -105.]],\n",
       " \n",
       "          [[  13.,   22.,   11.],\n",
       "           [  34.,  -73.,  -66.],\n",
       "           [  99.,  -54., -156.]],\n",
       " \n",
       "          [[ -12.,  -20.,  -48.],\n",
       "           [  -8.,  -56.,  -59.],\n",
       "           [  14.,  -35.,  -57.]]],\n",
       " \n",
       " \n",
       "         [[[  42.,   64.,  -33.],\n",
       "           [  16.,  156.,   70.],\n",
       "           [ -61.,  135.,  150.]],\n",
       " \n",
       "          [[ -12.,  -49.,  -27.],\n",
       "           [ -23.,  -89.,  -69.],\n",
       "           [  -9.,  -73.,  -74.]],\n",
       " \n",
       "          [[ -21.,   -1.,   51.],\n",
       "           [  11.,  -77.,  -19.],\n",
       "           [  70.,  -65.,  -99.]]],\n",
       " \n",
       " \n",
       "         [[[  -4.,   21.,  -10.],\n",
       "           [  91.,  -32.,  -57.],\n",
       "           [  50.,  -12.,   -9.]],\n",
       " \n",
       "          [[ -33.,    9.,  -19.],\n",
       "           [ 156.,  -66.,  -99.],\n",
       "           [  50.,  -42.,   -5.]],\n",
       " \n",
       "          [[   9.,   22.,  -18.],\n",
       "           [  53.,  -18.,  -44.],\n",
       "           [  28.,   -3.,   -4.]]],\n",
       " \n",
       " \n",
       "         [[[   1.,   -7.,    2.],\n",
       "           [ -42.,    1.,  109.],\n",
       "           [ -37.,   -1.,  110.]],\n",
       " \n",
       "          [[ -27.,  -54.,  -23.],\n",
       "           [ -55.,   13.,  168.],\n",
       "           [ -43.,   44.,  200.]],\n",
       " \n",
       "          [[  18.,   -7.,    1.],\n",
       "           [   5.,  -15.,   29.],\n",
       "           [  21.,  -13.,    8.]]],\n",
       " \n",
       " \n",
       "         [[[  -7.,    8.,  -13.],\n",
       "           [ -28.,   84.,  -54.],\n",
       "           [  -1.,   86.,  -91.]],\n",
       " \n",
       "          [[ -13.,   29.,  -15.],\n",
       "           [ -19.,  135.,  -94.],\n",
       "           [   0.,  126., -120.]],\n",
       " \n",
       "          [[  -7.,    1.,    2.],\n",
       "           [ -18.,   51.,  -34.],\n",
       "           [   2.,   48.,  -58.]]],\n",
       " \n",
       " \n",
       "         [[[   3.,  118.,  133.],\n",
       "           [  43.,   13.,   79.],\n",
       "           [  19.,  -28.,   41.]],\n",
       " \n",
       "          [[  65.,   88.,   50.],\n",
       "           [  64.,   57.,   96.],\n",
       "           [  51.,   21.,  112.]],\n",
       " \n",
       "          [[ 227.,  178.,  175.],\n",
       "           [ 127.,  124.,  211.],\n",
       "           [  81.,  106.,   80.]]],\n",
       " \n",
       " \n",
       "         [[[ -42.,  -79.,  -44.],\n",
       "           [-111., -109.,  -38.],\n",
       "           [ -29.,  -34.,  -50.]],\n",
       " \n",
       "          [[  96.,  121.,  136.],\n",
       "           [  27.,   73.,  132.],\n",
       "           [  74.,  112.,   67.]],\n",
       " \n",
       "          [[  15.,  -44.,  -60.],\n",
       "           [ -93., -119.,  -94.],\n",
       "           [ -37.,  -43.,  -85.]]],\n",
       " \n",
       " \n",
       "         [[[ -47.,   -5.,   29.],\n",
       "           [  62.,   79.,   14.],\n",
       "           [ -18.,  158.,  139.]],\n",
       " \n",
       "          [[  24.,   19.,  -11.],\n",
       "           [  56.,   92.,  -27.],\n",
       "           [ -85.,  137.,  170.]],\n",
       " \n",
       "          [[ -42.,  -57.,  -32.],\n",
       "           [  64.,   52.,   24.],\n",
       "           [  25.,  161.,  153.]]],\n",
       " \n",
       " \n",
       "         [[[ -48.,  -80.,  -27.],\n",
       "           [  43.,   59.,   17.],\n",
       "           [   0.,   18.,   33.]],\n",
       " \n",
       "          [[ -66., -139.,  -49.],\n",
       "           [  88.,  116.,   25.],\n",
       "           [ -21.,    0.,   16.]],\n",
       " \n",
       "          [[ -24.,  -39.,  -17.],\n",
       "           [  22.,   28.,   10.],\n",
       "           [  -2.,   10.,   23.]]],\n",
       " \n",
       " \n",
       "         [[[ 169.,    7.,    3.],\n",
       "           [  31.,  -24.,   -0.],\n",
       "           [  10.,    0.,   -9.]],\n",
       " \n",
       "          [[ 205.,   28.,   15.],\n",
       "           [   8.,  -17.,   20.],\n",
       "           [ -15.,    2.,  -13.]],\n",
       " \n",
       "          [[  94.,  -32.,  -17.],\n",
       "           [ -50.,  -28.,   -1.],\n",
       "           [   8.,   40.,  -15.]]],\n",
       " \n",
       " \n",
       "         [[[ 109.,   40.,   90.],\n",
       "           [  27.,  171.,    6.],\n",
       "           [ 139.,   89.,  116.]],\n",
       " \n",
       "          [[  -5.,   49.,  -19.],\n",
       "           [  37.,  -19.,  -12.],\n",
       "           [ 106.,   38.,  -12.]],\n",
       " \n",
       "          [[  61.,  -17.,  -12.],\n",
       "           [  49.,    4.,  -24.],\n",
       "           [  54.,   93.,  -84.]]],\n",
       " \n",
       " \n",
       "         [[[  95.,  149.,  166.],\n",
       "           [ 184.,  123.,  123.],\n",
       "           [ 165.,   29.,   81.]],\n",
       " \n",
       "          [[ -62.,  -45.,  -71.],\n",
       "           [ -53.,   14.,   46.],\n",
       "           [  18.,   26.,   26.]],\n",
       " \n",
       "          [[  37.,  -43.,  -26.],\n",
       "           [  15.,   20.,    2.],\n",
       "           [  68.,   67.,  -10.]]],\n",
       " \n",
       " \n",
       "         [[[  -2.,    3.,   29.],\n",
       "           [   9.,   65.,  145.],\n",
       "           [   4.,  -17.,    9.]],\n",
       " \n",
       "          [[ -16.,  -13.,   52.],\n",
       "           [ -10.,  103.,  205.],\n",
       "           [ -33.,  -16.,   -2.]],\n",
       " \n",
       "          [[   9.,  -35.,   -8.],\n",
       "           [  -7.,   22.,  125.],\n",
       "           [  -1.,  -50.,  -48.]]],\n",
       " \n",
       " \n",
       "         [[[  25.,   49.,   45.],\n",
       "           [ -30.,  -86.,    5.],\n",
       "           [ -49.,  -51.,    7.]],\n",
       " \n",
       "          [[-100.,  -57.,  -38.],\n",
       "           [-105., -173.,   -6.],\n",
       "           [-156., -119., -194.]],\n",
       " \n",
       "          [[  61.,   17.,   15.],\n",
       "           [  18.,  -67.,   10.],\n",
       "           [ -54.,  -45.,  -21.]]],\n",
       " \n",
       " \n",
       "         [[[ 134.,  -70.,  -79.],\n",
       "           [   4.,  -18.,  -51.],\n",
       "           [ -68.,   51.,  105.]],\n",
       " \n",
       "          [[ 109.,  -83., -121.],\n",
       "           [  -9.,   48.,  -52.],\n",
       "           [-119.,   91.,  128.]],\n",
       " \n",
       "          [[  81.,  -50.,  -51.],\n",
       "           [  24.,  -26.,  -33.],\n",
       "           [  -9.,   17.,   84.]]],\n",
       " \n",
       " \n",
       "         [[[  16.,  -47.,  -54.],\n",
       "           [ -43., -130., -140.],\n",
       "           [ -16.,  -73.,  -80.]],\n",
       " \n",
       "          [[  34.,   30.,   29.],\n",
       "           [  20.,    8.,   10.],\n",
       "           [  26.,   12.,    6.]],\n",
       " \n",
       "          [[ -38.,   20.,   30.],\n",
       "           [  13.,  101.,  115.],\n",
       "           [  -4.,   66.,   64.]]],\n",
       " \n",
       " \n",
       "         [[[ -72., -176.,  -36.],\n",
       "           [  26.,  -74.,  -61.],\n",
       "           [  73.,   79.,   29.]],\n",
       " \n",
       "          [[-117.,  -51.,   -4.],\n",
       "           [  11.,    9.,  -51.],\n",
       "           [  -1.,   76.,  -38.]],\n",
       " \n",
       "          [[  50., -125.,   10.],\n",
       "           [  11.,  -91.,  -74.],\n",
       "           [   7.,   41.,  -14.]]],\n",
       " \n",
       " \n",
       "         [[[   5.,  -21.,   74.],\n",
       "           [  73.,  -79.,  -14.],\n",
       "           [ -21.,   19.,   -8.]],\n",
       " \n",
       "          [[  -0.,  -43.,  111.],\n",
       "           [  73., -144.,  -19.],\n",
       "           [ -31.,   15.,   -8.]],\n",
       " \n",
       "          [[   4.,  -10.,   30.],\n",
       "           [  45.,  -52.,   -3.],\n",
       "           [ -16.,   34.,  -20.]]],\n",
       " \n",
       " \n",
       "         [[[  15.,   52.,   33.],\n",
       "           [  60.,   83.,   42.],\n",
       "           [ -39.,   -1.,   51.]],\n",
       " \n",
       "          [[ -80.,  -85.,  -50.],\n",
       "           [ -70.,  -91.,  -94.],\n",
       "           [-112., -117.,  -61.]],\n",
       " \n",
       "          [[ -33.,   61.,   79.],\n",
       "           [  59.,  138.,  103.],\n",
       "           [  -9.,   27.,   39.]]],\n",
       " \n",
       " \n",
       "         [[[  44.,   16.,    3.],\n",
       "           [  25.,    8.,  -42.],\n",
       "           [  10.,  -68., -112.]],\n",
       " \n",
       "          [[  83.,   46.,   10.],\n",
       "           [ 107.,   62.,   27.],\n",
       "           [  16.,   13.,  -18.]],\n",
       " \n",
       "          [[  81.,   89.,   33.],\n",
       "           [ 143.,   51.,   -2.],\n",
       "           [   0.,   -3.,  -84.]]],\n",
       " \n",
       " \n",
       "         [[[  74.,   65.,  -20.],\n",
       "           [  17.,  -27.,  -90.],\n",
       "           [  -1.,    3.,   28.]],\n",
       " \n",
       "          [[  56.,  -16., -147.],\n",
       "           [   5.,  -96., -181.],\n",
       "           [   9.,   13.,   59.]],\n",
       " \n",
       "          [[ -68.,  -33., -140.],\n",
       "           [ -23.,  -33., -105.],\n",
       "           [ -65.,   -5.,    5.]]],\n",
       " \n",
       " \n",
       "         [[[   7.,   17.,   13.],\n",
       "           [ -22.,   31.,   73.],\n",
       "           [  16.,  -48.,  -76.]],\n",
       " \n",
       "          [[   7.,   15.,   14.],\n",
       "           [ -33.,   56.,  123.],\n",
       "           [  26.,  -84., -132.]],\n",
       " \n",
       "          [[   9.,    8.,   10.],\n",
       "           [ -14.,   13.,   35.],\n",
       "           [  12.,  -26.,  -36.]]],\n",
       " \n",
       " \n",
       "         [[[   2.,   32.,  -28.],\n",
       "           [  51.,  -20.,  -41.],\n",
       "           [  49.,  -10.,  -90.]],\n",
       " \n",
       "          [[  38.,   20.,   -7.],\n",
       "           [  68., -105.,  -94.],\n",
       "           [ 118.,  -58., -137.]],\n",
       " \n",
       "          [[ -26.,   28.,   37.],\n",
       "           [  23.,   15.,   -8.],\n",
       "           [  36.,   35.,  -87.]]],\n",
       " \n",
       " \n",
       "         [[[  60.,   25.,   -8.],\n",
       "           [ -58.,  -33.,   54.],\n",
       "           [  60.,   25.,  -14.]],\n",
       " \n",
       "          [[  65.,  -24.,  -24.],\n",
       "           [-177., -181.,  -25.],\n",
       "           [  74.,   20.,  -33.]],\n",
       " \n",
       "          [[  50.,   33.,   11.],\n",
       "           [ -41.,   -7.,   46.],\n",
       "           [  47.,   22.,  -31.]]],\n",
       " \n",
       " \n",
       "         [[[ -54.,  -79.,   33.],\n",
       "           [  -6.,  -34.,   21.],\n",
       "           [ -55., -135.,  -13.]],\n",
       " \n",
       "          [[ -24.,  -63.,  -63.],\n",
       "           [  28.,    3.,  -30.],\n",
       "           [   7.,  -97.,   64.]],\n",
       " \n",
       "          [[  19.,  -24.,   49.],\n",
       "           [  -6., -166.,  -23.],\n",
       "           [  -3., -153.,   89.]]],\n",
       " \n",
       " \n",
       "         [[[  30.,   16.,   43.],\n",
       "           [  35.,  -25.,  -31.],\n",
       "           [  74.,  -33., -122.]],\n",
       " \n",
       "          [[  41.,   29.,   78.],\n",
       "           [  18.,  -73.,  -67.],\n",
       "           [  79.,  -50., -147.]],\n",
       " \n",
       "          [[  24.,   35.,   91.],\n",
       "           [  50.,  -10.,   -7.],\n",
       "           [  90.,  -57., -164.]]],\n",
       " \n",
       " \n",
       "         [[[ -77.,    4.,   78.],\n",
       "           [  38.,  143.,  172.],\n",
       "           [  74.,  111.,   59.]],\n",
       " \n",
       "          [[   7.,  -21.,  -20.],\n",
       "           [ -15.,  -62.,  -66.],\n",
       "           [ -17.,  -56.,  -47.]],\n",
       " \n",
       "          [[  41.,   -6.,  -53.],\n",
       "           [  -6.,  -76.,  -83.],\n",
       "           [ -60.,  -74.,    0.]]],\n",
       " \n",
       " \n",
       "         [[[  16.,  -62.,   38.],\n",
       "           [ -20., -107.,   92.],\n",
       "           [  -6.,  -90.,  126.]],\n",
       " \n",
       "          [[  -2.,  -93.,   27.],\n",
       "           [ -10., -107.,  113.],\n",
       "           [   9.,  -95.,  148.]],\n",
       " \n",
       "          [[ -11.,  -72.,    1.],\n",
       "           [ -16.,  -67.,   89.],\n",
       "           [  -4.,  -60.,  116.]]]], device='cuda:0'),\n",
       " tensor([[[[ -19.,  -23.,  -19.],\n",
       "           [ -39.,    8.,  216.],\n",
       "           [ -22.,  -18.,   16.]]],\n",
       " \n",
       " \n",
       "         [[[  -6.,  -16.,   23.],\n",
       "           [ -17.,  -41.,   99.],\n",
       "           [  34.,   17., -156.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.,  -34.,   14.],\n",
       "           [  -4.,  -52.,  203.],\n",
       "           [  -6.,  -42.,   27.]]],\n",
       " \n",
       " \n",
       "         [[[ -12.,   16.,  -13.],\n",
       "           [   3.,  176.,  -79.],\n",
       "           [  -6.,    9.,    5.]]],\n",
       " \n",
       " \n",
       "         [[[  39.,  127.,   41.],\n",
       "           [  16.,   38.,   22.],\n",
       "           [ -55., -128.,  -33.]]],\n",
       " \n",
       " \n",
       "         [[[ -11.,    5.,  -19.],\n",
       "           [  28.,   43., -140.],\n",
       "           [  13.,  115.,   26.]]],\n",
       " \n",
       " \n",
       "         [[[  10.,   27.,  -19.],\n",
       "           [   8.,    9., -115.],\n",
       "           [ -12.,  -34.,  140.]]],\n",
       " \n",
       " \n",
       "         [[[ -30.,  -15.,   42.],\n",
       "           [-118.,  -21.,  137.],\n",
       "           [ -31.,  -13.,   34.]]],\n",
       " \n",
       " \n",
       "         [[[  -7.,   61.,  -49.],\n",
       "           [  16., -187.,   60.],\n",
       "           [  -4.,   68.,  -35.]]],\n",
       " \n",
       " \n",
       "         [[[-133.,  -38.,  -42.],\n",
       "           [ -88.,   44.,  -11.],\n",
       "           [-211.,  -94.,  -46.]]],\n",
       " \n",
       " \n",
       "         [[[  20.,  -31., -133.],\n",
       "           [ -36.,   46.,  104.],\n",
       "           [-107.,   80.,  122.]]],\n",
       " \n",
       " \n",
       "         [[[  32.,  135.,   90.],\n",
       "           [  12.,   21.,   -5.],\n",
       "           [ -30., -120.,  -90.]]],\n",
       " \n",
       " \n",
       "         [[[  -6.,   20.,    7.],\n",
       "           [   0.,  -30., -137.],\n",
       "           [  20.,   54.,  118.]]],\n",
       " \n",
       " \n",
       "         [[[ -25.,   -3.,  -39.],\n",
       "           [   2.,   11.,  -38.],\n",
       "           [ -40.,  -39.,  215.]]],\n",
       " \n",
       " \n",
       "         [[[ -11.,  -28.,   70.],\n",
       "           [-185.,  -22.,  -18.],\n",
       "           [-165., -104.,  -96.]]],\n",
       " \n",
       " \n",
       "         [[[  49., -145., -122.],\n",
       "           [ -53., -164., -206.],\n",
       "           [ -30., -167., -183.]]],\n",
       " \n",
       " \n",
       "         [[[ -64.,  -49.,  -36.],\n",
       "           [  23.,   41.,  -49.],\n",
       "           [  -2.,  191.,  -19.]]],\n",
       " \n",
       " \n",
       "         [[[ -46.,    6.,  105.],\n",
       "           [-150.,  -75.,   85.],\n",
       "           [ -61.,  -24.,   83.]]],\n",
       " \n",
       " \n",
       "         [[[ -11.,   -5.,  -19.],\n",
       "           [  43., -140.,  115.],\n",
       "           [  -7.,   -4.,   14.]]],\n",
       " \n",
       " \n",
       "         [[[  24.,  -32.,  -88.],\n",
       "           [ -85.,   52.,  167.],\n",
       "           [ -39.,   17.,   26.]]],\n",
       " \n",
       " \n",
       "         [[[   7.,   30.,  -13.],\n",
       "           [  32.,   34.,  -36.],\n",
       "           [ -44.,  -38.,  211.]]],\n",
       " \n",
       " \n",
       "         [[[  27.,    4.,   18.],\n",
       "           [  15.,  -23.,  -28.],\n",
       "           [  29.,  103., -152.]]],\n",
       " \n",
       " \n",
       "         [[[  35.,  -24., -118.],\n",
       "           [ -30.,   35.,  137.],\n",
       "           [ -46.,   59.,  133.]]],\n",
       " \n",
       " \n",
       "         [[[ -42.,  -22.,  -65.],\n",
       "           [  -9.,  -29.,  -84.],\n",
       "           [-129.,   -6.,  126.]]],\n",
       " \n",
       " \n",
       "         [[[  12.,   49.,   26.],\n",
       "           [  42.,  -97.,  -56.],\n",
       "           [ 123.,  -55., -132.]]],\n",
       " \n",
       " \n",
       "         [[[   5.,   -6.,   10.],\n",
       "           [  -8.,  198.,  -57.],\n",
       "           [   1.,   19.,  -29.]]],\n",
       " \n",
       " \n",
       "         [[[  -2.,  -22.,   -3.],\n",
       "           [  34.,  167.,  -88.],\n",
       "           [ -14.,  -28.,   -2.]]],\n",
       " \n",
       " \n",
       "         [[[  -4.,  -20., -112.],\n",
       "           [ -33.,  -44.,  143.],\n",
       "           [ -41.,   67.,  130.]]],\n",
       " \n",
       " \n",
       "         [[[  12.,   22.,   60.],\n",
       "           [  53.,   97., -158.],\n",
       "           [  74.,   65.,  -55.]]],\n",
       " \n",
       " \n",
       "         [[[ 147.,   60.,   67.],\n",
       "           [   9., -108.,  -82.],\n",
       "           [  87.,   -7., -105.]]],\n",
       " \n",
       " \n",
       "         [[[  24.,  -45.,  -94.],\n",
       "           [ -64.,  -22.,  161.],\n",
       "           [ -64.,   42.,   80.]]],\n",
       " \n",
       " \n",
       "         [[[  62., -119.,   27.],\n",
       "           [ 136., -105.,   -4.],\n",
       "           [ 134.,  -65.,   70.]]]], device='cuda:0'),\n",
       " tensor([[[[  -2.]],\n",
       " \n",
       "          [[  25.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[ -22.]],\n",
       " \n",
       "          [[ 169.]],\n",
       " \n",
       "          [[  55.]],\n",
       " \n",
       "          [[  -8.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[  57.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          [[ -27.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ 102.]],\n",
       " \n",
       "          [[ -86.]],\n",
       " \n",
       "          [[ -42.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[  50.]],\n",
       " \n",
       "          [[  48.]],\n",
       " \n",
       "          [[   6.]],\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[  26.]],\n",
       " \n",
       "          [[ 116.]],\n",
       " \n",
       "          [[  31.]]],\n",
       " \n",
       " \n",
       "         [[[   5.]],\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[-123.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[  50.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[ -30.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  67.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[ -30.]],\n",
       " \n",
       "          [[  56.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  49.]],\n",
       " \n",
       "          [[ 132.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ -49.]],\n",
       " \n",
       "          [[  27.]],\n",
       " \n",
       "          [[ -46.]],\n",
       " \n",
       "          [[  81.]],\n",
       " \n",
       "          [[ -77.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  63.]],\n",
       " \n",
       "          [[-104.]]],\n",
       " \n",
       " \n",
       "         [[[  -3.]],\n",
       " \n",
       "          [[ 154.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[ 136.]],\n",
       " \n",
       "          [[ -34.]],\n",
       " \n",
       "          [[ -65.]],\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          [[  12.]],\n",
       " \n",
       "          [[ -77.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[  54.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[  -6.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          [[  26.]],\n",
       " \n",
       "          [[  25.]],\n",
       " \n",
       "          [[ 145.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[-101.]],\n",
       " \n",
       "          [[ -11.]],\n",
       " \n",
       "          [[ 105.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  27.]],\n",
       " \n",
       "          [[ -30.]],\n",
       " \n",
       "          [[  38.]]],\n",
       " \n",
       " \n",
       "         [[[  10.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[ -29.]],\n",
       " \n",
       "          [[  30.]],\n",
       " \n",
       "          [[ 113.]],\n",
       " \n",
       "          [[-142.]],\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          [[ -98.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[ 110.]],\n",
       " \n",
       "          [[-106.]],\n",
       " \n",
       "          [[ 101.]],\n",
       " \n",
       "          [[  93.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[ -21.]],\n",
       " \n",
       "          [[-108.]],\n",
       " \n",
       "          [[ -31.]],\n",
       " \n",
       "          [[  73.]],\n",
       " \n",
       "          [[-101.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ -88.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          [[-126.]],\n",
       " \n",
       "          [[-131.]],\n",
       " \n",
       "          [[-116.]],\n",
       " \n",
       "          [[  82.]],\n",
       " \n",
       "          [[ -23.]],\n",
       " \n",
       "          [[  11.]]],\n",
       " \n",
       " \n",
       "         [[[  -5.]],\n",
       " \n",
       "          [[-111.]],\n",
       " \n",
       "          [[  48.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[-146.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ -71.]],\n",
       " \n",
       "          [[  83.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          [[  -5.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ 108.]],\n",
       " \n",
       "          [[  45.]],\n",
       " \n",
       "          [[ -80.]],\n",
       " \n",
       "          [[  46.]],\n",
       " \n",
       "          [[ -63.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[  60.]],\n",
       " \n",
       "          [[ -36.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[  77.]],\n",
       " \n",
       "          [[ 109.]]],\n",
       " \n",
       " \n",
       "         [[[  -0.]],\n",
       " \n",
       "          [[ -60.]],\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[-138.]],\n",
       " \n",
       "          [[ -57.]],\n",
       " \n",
       "          [[ -67.]],\n",
       " \n",
       "          [[ 103.]],\n",
       " \n",
       "          [[ 117.]],\n",
       " \n",
       "          [[ 116.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[ 105.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  15.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[ -31.]],\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[ -74.]],\n",
       " \n",
       "          [[  52.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  51.]],\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[  23.]],\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          [[-138.]],\n",
       " \n",
       "          [[ -69.]]],\n",
       " \n",
       " \n",
       "         [[[   0.]],\n",
       " \n",
       "          [[  77.]],\n",
       " \n",
       "          [[ -23.]],\n",
       " \n",
       "          [[-100.]],\n",
       " \n",
       "          [[ -62.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[-172.]],\n",
       " \n",
       "          [[  38.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[ -48.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ -64.]],\n",
       " \n",
       "          [[ -13.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[  83.]],\n",
       " \n",
       "          [[  27.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[  26.]],\n",
       " \n",
       "          [[ -72.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[  25.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[ -13.]]],\n",
       " \n",
       " \n",
       "         [[[ -10.]],\n",
       " \n",
       "          [[  -5.]],\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[  77.]],\n",
       " \n",
       "          [[ 127.]],\n",
       " \n",
       "          [[ -55.]],\n",
       " \n",
       "          [[  45.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  66.]],\n",
       " \n",
       "          [[-128.]],\n",
       " \n",
       "          [[ -68.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[  83.]],\n",
       " \n",
       "          [[ -42.]],\n",
       " \n",
       "          [[  86.]],\n",
       " \n",
       "          [[ -45.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[  30.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[  49.]],\n",
       " \n",
       "          [[ 123.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[  34.]]],\n",
       " \n",
       " \n",
       "         [[[  12.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[  68.]],\n",
       " \n",
       "          [[ -78.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[ 105.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[ -28.]],\n",
       " \n",
       "          [[  60.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  61.]],\n",
       " \n",
       "          [[  56.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[  40.]],\n",
       " \n",
       "          [[ 103.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[-113.]],\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          [[ -55.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[ -79.]],\n",
       " \n",
       "          [[ -50.]],\n",
       " \n",
       "          [[ -29.]],\n",
       " \n",
       "          [[ 142.]]],\n",
       " \n",
       " \n",
       "         [[[  -3.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[ -13.]],\n",
       " \n",
       "          [[ -81.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[ -21.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[  38.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[ 143.]],\n",
       " \n",
       "          [[  -6.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ -53.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[ -44.]],\n",
       " \n",
       "          [[  65.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  84.]],\n",
       " \n",
       "          [[  85.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[ 174.]],\n",
       " \n",
       "          [[ -17.]]],\n",
       " \n",
       " \n",
       "         [[[   3.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[ -31.]],\n",
       " \n",
       "          [[  11.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  78.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  15.]],\n",
       " \n",
       "          [[ -21.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[-177.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ -44.]],\n",
       " \n",
       "          [[ -21.]],\n",
       " \n",
       "          [[  23.]],\n",
       " \n",
       "          [[  12.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[ -30.]],\n",
       " \n",
       "          [[ -33.]],\n",
       " \n",
       "          [[ -21.]]],\n",
       " \n",
       " \n",
       "         [[[   3.]],\n",
       " \n",
       "          [[ -45.]],\n",
       " \n",
       "          [[  69.]],\n",
       " \n",
       "          [[  35.]],\n",
       " \n",
       "          [[ -23.]],\n",
       " \n",
       "          [[ -55.]],\n",
       " \n",
       "          [[ -69.]],\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[-141.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[ -36.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[ -77.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ -82.]],\n",
       " \n",
       "          [[ -74.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[  61.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          [[  87.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[ 114.]],\n",
       " \n",
       "          [[ -49.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[  61.]],\n",
       " \n",
       "          [[  56.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.]],\n",
       " \n",
       "          [[ 148.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[ -53.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[-101.]],\n",
       " \n",
       "          [[-107.]],\n",
       " \n",
       "          [[  35.]],\n",
       " \n",
       "          [[  54.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[ -34.]],\n",
       " \n",
       "          [[ -57.]],\n",
       " \n",
       "          [[  97.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[ -27.]],\n",
       " \n",
       "          [[  67.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  33.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[ -44.]],\n",
       " \n",
       "          [[  36.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  50.]],\n",
       " \n",
       "          [[ -40.]]],\n",
       " \n",
       " \n",
       "         [[[  -5.]],\n",
       " \n",
       "          [[ -36.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          [[  30.]],\n",
       " \n",
       "          [[ -11.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          [[ -94.]],\n",
       " \n",
       "          [[ -81.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[ -20.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[ 129.]],\n",
       " \n",
       "          [[ -35.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[  51.]],\n",
       " \n",
       "          [[  -5.]],\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  40.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[  77.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[-126.]],\n",
       " \n",
       "          [[  89.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[-108.]],\n",
       " \n",
       "          [[  29.]],\n",
       " \n",
       "          [[-169.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  29.]],\n",
       " \n",
       "          [[  86.]],\n",
       " \n",
       "          [[  25.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[  35.]],\n",
       " \n",
       "          [[ -54.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[ -90.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[  -5.]]],\n",
       " \n",
       " \n",
       "         [[[  -0.]],\n",
       " \n",
       "          [[ -82.]],\n",
       " \n",
       "          [[ -56.]],\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          [[  82.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[-109.]],\n",
       " \n",
       "          [[ -43.]],\n",
       " \n",
       "          [[  89.]],\n",
       " \n",
       "          [[   0.]],\n",
       " \n",
       "          [[ -89.]],\n",
       " \n",
       "          [[ -70.]],\n",
       " \n",
       "          [[ -85.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  93.]],\n",
       " \n",
       "          [[-122.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[  95.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[ -49.]],\n",
       " \n",
       "          [[ 133.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[ -92.]],\n",
       " \n",
       "          [[ -33.]]]], device='cuda:0'),\n",
       " tensor([[[[ 54.]],\n",
       " \n",
       "          [[ 10.]],\n",
       " \n",
       "          [[ 45.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-49.]],\n",
       " \n",
       "          [[-66.]],\n",
       " \n",
       "          [[-80.]]],\n",
       " \n",
       " \n",
       "         [[[ 30.]],\n",
       " \n",
       "          [[ 43.]],\n",
       " \n",
       "          [[ 73.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 42.]],\n",
       " \n",
       "          [[  4.]],\n",
       " \n",
       "          [[-56.]]],\n",
       " \n",
       " \n",
       "         [[[-45.]],\n",
       " \n",
       "          [[-31.]],\n",
       " \n",
       "          [[-79.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-77.]],\n",
       " \n",
       "          [[-94.]],\n",
       " \n",
       "          [[ 51.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 43.]],\n",
       " \n",
       "          [[ 30.]],\n",
       " \n",
       "          [[ 19.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-62.]],\n",
       " \n",
       "          [[ 72.]],\n",
       " \n",
       "          [[-82.]]],\n",
       " \n",
       " \n",
       "         [[[126.]],\n",
       " \n",
       "          [[ 63.]],\n",
       " \n",
       "          [[-56.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-57.]],\n",
       " \n",
       "          [[-12.]],\n",
       " \n",
       "          [[-63.]]],\n",
       " \n",
       " \n",
       "         [[[-90.]],\n",
       " \n",
       "          [[ -9.]],\n",
       " \n",
       "          [[-98.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -8.]],\n",
       " \n",
       "          [[-26.]],\n",
       " \n",
       "          [[ 10.]]]], device='cuda:0'),\n",
       " tensor([[[[-160., -276., -148.],\n",
       "           [-320., -321., -226.],\n",
       "           [ -66., -201.,  -67.]]],\n",
       " \n",
       " \n",
       "         [[[-171.,  -88.,   -2.],\n",
       "           [-257., -101.,   -6.],\n",
       "           [-214., -193.,  -64.]]],\n",
       " \n",
       " \n",
       "         [[[ -42.,  -18.,   18.],\n",
       "           [  57.,  130.,   58.],\n",
       "           [  -9.,  -51., -125.]]],\n",
       " \n",
       " \n",
       "         [[[ 168.,  142.,  -83.],\n",
       "           [ 134.,  166.,  -45.],\n",
       "           [ -15.,    3.,  -87.]]],\n",
       " \n",
       " \n",
       "         [[[ -29., -103.,  -54.],\n",
       "           [ -32.,  -44.,   -1.],\n",
       "           [  45.,  152.,   69.]]],\n",
       " \n",
       " \n",
       "         [[[  17.,  144.,  123.],\n",
       "           [ -41.,  -55.,   42.],\n",
       "           [ -59., -111.,  -71.]]],\n",
       " \n",
       " \n",
       "         [[[  36.,  117.,   19.],\n",
       "           [ 127.,  104., -111.],\n",
       "           [  95.,   13., -128.]]],\n",
       " \n",
       " \n",
       "         [[[-107.,   36.,  -99.],\n",
       "           [-106.,  128., -121.],\n",
       "           [-127.,   74.,  -91.]]],\n",
       " \n",
       " \n",
       "         [[[  68.,   39.,   14.],\n",
       "           [  44.,  245.,  235.],\n",
       "           [ -10.,  236.,  220.]]],\n",
       " \n",
       " \n",
       "         [[[ -48.,   98.,  -31.],\n",
       "           [ -16.,   55.,  -32.],\n",
       "           [  64., -157.,   60.]]],\n",
       " \n",
       " \n",
       "         [[[  56.,   44.,   27.],\n",
       "           [ 111.,  282.,   98.],\n",
       "           [ 161.,  218.,  106.]]],\n",
       " \n",
       " \n",
       "         [[[ -55., -187., -214.],\n",
       "           [ -29., -254., -238.],\n",
       "           [   1.,   -7.,  -47.]]],\n",
       " \n",
       " \n",
       "         [[[ -45.,   49.,  -10.],\n",
       "           [  96., -150.,   51.],\n",
       "           [ -51.,  105.,  -47.]]],\n",
       " \n",
       " \n",
       "         [[[ -46.,   -6.,   35.],\n",
       "           [-111.,  144.,   15.],\n",
       "           [  27.,   99.,  -52.]]],\n",
       " \n",
       " \n",
       "         [[[ -18.,  -38.,  -28.],\n",
       "           [  40.,  149.,   34.],\n",
       "           [ -16., -106.,   -4.]]],\n",
       " \n",
       " \n",
       "         [[[ -96., -136.,  -35.],\n",
       "           [-249., -290., -132.],\n",
       "           [-133., -267., -126.]]],\n",
       " \n",
       " \n",
       "         [[[-128., -106.,  -41.],\n",
       "           [ -32.,   48.,   79.],\n",
       "           [ -14.,   66.,  127.]]],\n",
       " \n",
       " \n",
       "         [[[ 113.,  259.,   93.],\n",
       "           [ 189.,  134.,    4.],\n",
       "           [  35.,  122.,   15.]]],\n",
       " \n",
       " \n",
       "         [[[ -21.,  -79.,    4.],\n",
       "           [  -3., -250.,  -71.],\n",
       "           [  -0., -124.,    5.]]],\n",
       " \n",
       " \n",
       "         [[[ -32.,  -88.,  -69.],\n",
       "           [ -82., -253., -186.],\n",
       "           [   2., -184., -121.]]],\n",
       " \n",
       " \n",
       "         [[[  80.,   62.,   -7.],\n",
       "           [ 101.,  225.,   12.],\n",
       "           [  80.,   56.,  -30.]]],\n",
       " \n",
       " \n",
       "         [[[ -21.,    4.,   59.],\n",
       "           [ -23.,  -91.,  164.],\n",
       "           [  25.,  -21.,  104.]]],\n",
       " \n",
       " \n",
       "         [[[  38.,  -92.,   49.],\n",
       "           [ -98.,  157.,  -54.],\n",
       "           [  61.,  -62.,   10.]]],\n",
       " \n",
       " \n",
       "         [[[ -12.,   20.,   -6.],\n",
       "           [  26., -138.,  112.],\n",
       "           [ -14.,  117.,  -99.]]],\n",
       " \n",
       " \n",
       "         [[[ -38.,  -56.,   35.],\n",
       "           [  15.,  -77., -149.],\n",
       "           [   8.,  106.,    7.]]],\n",
       " \n",
       " \n",
       "         [[[  -5.,  109.,  126.],\n",
       "           [  31.,  250.,  234.],\n",
       "           [  55.,  173.,  133.]]],\n",
       " \n",
       " \n",
       "         [[[ -17.,  -63.,  -30.],\n",
       "           [  77.,  188.,   79.],\n",
       "           [ -23.,  -67.,  -21.]]],\n",
       " \n",
       " \n",
       "         [[[ 125.,  139.,  161.],\n",
       "           [  49.,  245.,  218.],\n",
       "           [ -10.,   97.,  100.]]],\n",
       " \n",
       " \n",
       "         [[[  86.,  117.,   30.],\n",
       "           [  89.,  208.,   53.],\n",
       "           [ -27.,  -20.,  -47.]]],\n",
       " \n",
       " \n",
       "         [[[ -43.,   87.,  -43.],\n",
       "           [  77.,  -65.,  -19.],\n",
       "           [  48., -164.,   91.]]],\n",
       " \n",
       " \n",
       "         [[[-104., -258., -160.],\n",
       "           [-242., -308., -233.],\n",
       "           [-110., -200.,  -53.]]],\n",
       " \n",
       " \n",
       "         [[[  46.,  -22.,  -23.],\n",
       "           [ -19.,  152.,  -47.],\n",
       "           [-103.,   29.,   66.]]],\n",
       " \n",
       " \n",
       "         [[[ -23.,   25.,  -19.],\n",
       "           [ -72.,  183.,  -45.],\n",
       "           [ -26.,   99.,  -23.]]],\n",
       " \n",
       " \n",
       "         [[[ -47., -186., -174.],\n",
       "           [-102., -278., -253.],\n",
       "           [ -23., -102., -135.]]],\n",
       " \n",
       " \n",
       "         [[[-167., -223.,  -12.],\n",
       "           [-171., -265.,  -93.],\n",
       "           [ -10.,  -73.,  -48.]]],\n",
       " \n",
       " \n",
       "         [[[ -16.,   41.,  -26.],\n",
       "           [ -51.,  167.,  -87.],\n",
       "           [ -46.,  143.,  -88.]]],\n",
       " \n",
       " \n",
       "         [[[-247., -208.,    8.],\n",
       "           [ -83.,  -87.,  -64.],\n",
       "           [  -8., -217.,  -99.]]],\n",
       " \n",
       " \n",
       "         [[[ -70.,  114.,  185.],\n",
       "           [ -45.,  140.,  148.],\n",
       "           [  -5.,   -3.,  -25.]]],\n",
       " \n",
       " \n",
       "         [[[ -36.,   76.,  -35.],\n",
       "           [  77., -172.,   83.],\n",
       "           [ -32.,   68.,  -37.]]],\n",
       " \n",
       " \n",
       "         [[[  33.,   -2.,   18.],\n",
       "           [ -12.,  230.,  243.],\n",
       "           [  17.,  236.,  222.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.,  -52.,   -1.],\n",
       "           [-234., -256.,  -43.],\n",
       "           [ -82., -248.,   -4.]]],\n",
       " \n",
       " \n",
       "         [[[ 182.,  177.,  -65.],\n",
       "           [ 190.,  185.,  -63.],\n",
       "           [  27.,   17.,  -11.]]],\n",
       " \n",
       " \n",
       "         [[[ -17., -100.,  -78.],\n",
       "           [  80.,   14., -126.],\n",
       "           [ -27.,  129.,   39.]]],\n",
       " \n",
       " \n",
       "         [[[ -16.,  -59.,   76.],\n",
       "           [ -17.,  -94.,  161.],\n",
       "           [   6.,  -81.,   98.]]],\n",
       " \n",
       " \n",
       "         [[[  72.,  -50.,  -15.],\n",
       "           [ 167.,  -88.,  -23.],\n",
       "           [  79.,  -47.,  -26.]]],\n",
       " \n",
       " \n",
       "         [[[ 104.,  145.,   47.],\n",
       "           [  83.,  232.,  180.],\n",
       "           [ -23.,  117.,  133.]]],\n",
       " \n",
       " \n",
       "         [[[ -47.,  -80.,    5.],\n",
       "           [-140., -242.,   13.],\n",
       "           [ -87., -179.,  -34.]]],\n",
       " \n",
       " \n",
       "         [[[   9.,  -83.,   57.],\n",
       "           [ 108.,  -31.,  -94.],\n",
       "           [-102.,  153.,  -15.]]],\n",
       " \n",
       " \n",
       "         [[[  22.,  -79.,   -7.],\n",
       "           [-114.,  -70.,   90.],\n",
       "           [  27.,  141.,  -31.]]],\n",
       " \n",
       " \n",
       "         [[[   9.,  -13.,   -9.],\n",
       "           [  86., -149.,   55.],\n",
       "           [  87., -168.,   73.]]],\n",
       " \n",
       " \n",
       "         [[[  73.,   52.,   83.],\n",
       "           [ 144.,  275.,  185.],\n",
       "           [  20.,  153.,   64.]]],\n",
       " \n",
       " \n",
       "         [[[ -50., -182., -238.],\n",
       "           [-170., -305., -243.],\n",
       "           [ -81., -189., -112.]]],\n",
       " \n",
       " \n",
       "         [[[ -23.,  -32.,  -70.],\n",
       "           [ -62.,  -57., -278.],\n",
       "           [ -26.,  -40.,  -58.]]],\n",
       " \n",
       " \n",
       "         [[[  72.,  112.,   14.],\n",
       "           [ -93.,  162.,  128.],\n",
       "           [ -35.,    8.,   74.]]],\n",
       " \n",
       " \n",
       "         [[[-126.,  -91.,   12.],\n",
       "           [-204., -215.,   40.],\n",
       "           [-156., -144.,  -11.]]],\n",
       " \n",
       " \n",
       "         [[[  10.,   88.,    5.],\n",
       "           [ -28., -167.,  -31.],\n",
       "           [  13.,   69.,   14.]]],\n",
       " \n",
       " \n",
       "         [[[ -23.,   71.,  113.],\n",
       "           [  78.,  232.,  195.],\n",
       "           [ 126.,  188.,   75.]]],\n",
       " \n",
       " \n",
       "         [[[ -88., -179.,  -84.],\n",
       "           [ -89., -247.,  -89.],\n",
       "           [ -37.,  -92.,    8.]]],\n",
       " \n",
       " \n",
       "         [[[  -9.,  -73.,   60.],\n",
       "           [  -2., -136.,  119.],\n",
       "           [  -1.,  -49.,   59.]]],\n",
       " \n",
       " \n",
       "         [[[ 143.,  235.,  116.],\n",
       "           [ 169.,  242.,  112.],\n",
       "           [  17.,   15.,  -13.]]],\n",
       " \n",
       " \n",
       "         [[[ -20.,  -12.,   32.],\n",
       "           [  29.,  235.,  187.],\n",
       "           [  69.,  188.,  106.]]],\n",
       " \n",
       " \n",
       "         [[[  71.,   84.,  -26.],\n",
       "           [  66.,  224.,  170.],\n",
       "           [ -31.,  184.,  192.]]],\n",
       " \n",
       " \n",
       "         [[[ -79.,   85.,  -16.],\n",
       "           [ 108., -147.,   36.],\n",
       "           [ -26.,   43.,  -17.]]],\n",
       " \n",
       " \n",
       "         [[[   0.,  -29., -119.],\n",
       "           [  40.,  -44., -193.],\n",
       "           [  62.,  -79.,  -88.]]],\n",
       " \n",
       " \n",
       "         [[[-145., -203.,  -85.],\n",
       "           [-254., -305., -172.],\n",
       "           [-133., -186.,  -50.]]],\n",
       " \n",
       " \n",
       "         [[[ -30.,   -5.,    7.],\n",
       "           [ 141.,   64.,   -4.],\n",
       "           [-114.,  -73.,   -7.]]],\n",
       " \n",
       " \n",
       "         [[[ -61., -125.,   -4.],\n",
       "           [  24.,  130.,    7.],\n",
       "           [  15.,  -26.,  -17.]]],\n",
       " \n",
       " \n",
       "         [[[ -25., -153.,  -59.],\n",
       "           [-138., -266., -280.],\n",
       "           [-145., -184., -257.]]],\n",
       " \n",
       " \n",
       "         [[[ 144.,   40.,   17.],\n",
       "           [ 182.,  201.,  -54.],\n",
       "           [ -23.,  161.,   44.]]],\n",
       " \n",
       " \n",
       "         [[[  69.,  -68.,  -19.],\n",
       "           [ 124., -131.,  -83.],\n",
       "           [ 103.,  -45.,  -18.]]],\n",
       " \n",
       " \n",
       "         [[[  77.,  221.,  191.],\n",
       "           [ 236.,  176.,  -19.],\n",
       "           [  64.,   31.,    1.]]],\n",
       " \n",
       " \n",
       "         [[[ -35.,  -81.,  -16.],\n",
       "           [-126., -271.,  -61.],\n",
       "           [ -97., -175.,  -70.]]],\n",
       " \n",
       " \n",
       "         [[[  14.,    4.,   17.],\n",
       "           [  66.,  109.,   69.],\n",
       "           [ -78., -146.,  -65.]]],\n",
       " \n",
       " \n",
       "         [[[  38.,  136.,  146.],\n",
       "           [-109.,  -24.,  109.],\n",
       "           [  48.,   13.,   54.]]],\n",
       " \n",
       " \n",
       "         [[[  64.,  -93.,  -42.],\n",
       "           [-138.,  -56.,  106.],\n",
       "           [  44.,  117.,   30.]]],\n",
       " \n",
       " \n",
       "         [[[  21.,  -76.,  -77.],\n",
       "           [ -76., -234., -133.],\n",
       "           [-148., -197.,   -5.]]],\n",
       " \n",
       " \n",
       "         [[[  -8.,  -12.,   10.],\n",
       "           [ 177.,  204.,   45.],\n",
       "           [ 206.,  243.,   61.]]],\n",
       " \n",
       " \n",
       "         [[[ -97., -106., -120.],\n",
       "           [  -8.,  -93., -263.],\n",
       "           [-137., -220., -200.]]],\n",
       " \n",
       " \n",
       "         [[[  50.,   76.,   52.],\n",
       "           [ -71., -179.,  -67.],\n",
       "           [  19.,   66.,   21.]]],\n",
       " \n",
       " \n",
       "         [[[  46.,    6.,  -52.],\n",
       "           [ 142.,   -8., -113.],\n",
       "           [ 101.,    8.,  -55.]]],\n",
       " \n",
       " \n",
       "         [[[ -79., -203., -108.],\n",
       "           [-290., -334., -259.],\n",
       "           [-156., -250., -144.]]],\n",
       " \n",
       " \n",
       "         [[[  72.,  103.,    3.],\n",
       "           [ 126.,  141.,  -25.],\n",
       "           [  46.,  125., -114.]]],\n",
       " \n",
       " \n",
       "         [[[-107.,   31.,   28.],\n",
       "           [-205.,  -31.,   45.],\n",
       "           [-181.,  -28.,   50.]]],\n",
       " \n",
       " \n",
       "         [[[ 102.,  105.,  -32.],\n",
       "           [  38.,  194.,  167.],\n",
       "           [ -61.,  106.,  150.]]],\n",
       " \n",
       " \n",
       "         [[[ -42., -123.,  -85.],\n",
       "           [ -90., -297., -127.],\n",
       "           [ -58., -157., -106.]]],\n",
       " \n",
       " \n",
       "         [[[   1.,   45.,   66.],\n",
       "           [  25.,  256.,  184.],\n",
       "           [  48.,  138.,  153.]]],\n",
       " \n",
       " \n",
       "         [[[ -83.,   34.,   34.],\n",
       "           [  -9.,  172.,  -72.],\n",
       "           [  99.,  -68.,  -81.]]],\n",
       " \n",
       " \n",
       "         [[[  67.,   76.,   36.],\n",
       "           [ 133.,  291.,  183.],\n",
       "           [  75.,  241.,  167.]]],\n",
       " \n",
       " \n",
       "         [[[ -73., -145.,  -36.],\n",
       "           [-233., -275., -189.],\n",
       "           [-212., -254., -291.]]],\n",
       " \n",
       " \n",
       "         [[[  28.,  -17., -115.],\n",
       "           [  -5.,  140.,   12.],\n",
       "           [ -80.,  -23.,   47.]]],\n",
       " \n",
       " \n",
       "         [[[  12.,  -13.,   -3.],\n",
       "           [ -54.,  136.,  -79.],\n",
       "           [  43., -119.,   76.]]],\n",
       " \n",
       " \n",
       "         [[[-170., -197.,  -85.],\n",
       "           [-227., -323., -187.],\n",
       "           [ -68., -215., -127.]]],\n",
       " \n",
       " \n",
       "         [[[ -84., -146., -157.],\n",
       "           [-132., -339., -305.],\n",
       "           [ -92., -310., -262.]]],\n",
       " \n",
       " \n",
       "         [[[ 173.,  181.,  -74.],\n",
       "           [ 176.,  180.,  -66.],\n",
       "           [ -24.,  -55.,   -4.]]],\n",
       " \n",
       " \n",
       "         [[[ -96., -116.,  -63.],\n",
       "           [-247., -206.,  -28.],\n",
       "           [ -87.,  -64.,    8.]]],\n",
       " \n",
       " \n",
       "         [[[  36.,  127.,   93.],\n",
       "           [ -31., -128.,  -82.],\n",
       "           [ -14.,  -26.,   -2.]]]], device='cuda:0'),\n",
       " tensor([[[[  57.]],\n",
       " \n",
       "          [[  59.]],\n",
       " \n",
       "          [[  -8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -20.]],\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[ -32.]]],\n",
       " \n",
       " \n",
       "         [[[   5.]],\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[  54.]]],\n",
       " \n",
       " \n",
       "         [[[  55.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[ -65.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[-103.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[   9.]],\n",
       " \n",
       "          [[ -24.]],\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -23.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  11.]]],\n",
       " \n",
       " \n",
       "         [[[  60.]],\n",
       " \n",
       "          [[ -33.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -60.]],\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          [[  62.]]],\n",
       " \n",
       " \n",
       "         [[[ -20.]],\n",
       " \n",
       "          [[ -32.]],\n",
       " \n",
       "          [[  43.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  65.]],\n",
       " \n",
       "          [[  75.]],\n",
       " \n",
       "          [[  15.]]]], device='cuda:0'),\n",
       " tensor([[[[  -9.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[ -97.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  61.]],\n",
       " \n",
       "          [[  29.]],\n",
       " \n",
       "          [[ -15.]]],\n",
       " \n",
       " \n",
       "         [[[ -44.]],\n",
       " \n",
       "          [[ 148.]],\n",
       " \n",
       "          [[ -29.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[-107.]],\n",
       " \n",
       "          [[ -29.]]],\n",
       " \n",
       " \n",
       "         [[[  80.]],\n",
       " \n",
       "          [[ -46.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  59.]],\n",
       " \n",
       "          [[ 107.]],\n",
       " \n",
       "          [[ -28.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  32.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[  30.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-101.]],\n",
       " \n",
       "          [[ -57.]],\n",
       " \n",
       "          [[ -77.]]],\n",
       " \n",
       " \n",
       "         [[[-124.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 103.]],\n",
       " \n",
       "          [[ 131.]],\n",
       " \n",
       "          [[  46.]]],\n",
       " \n",
       " \n",
       "         [[[  58.]],\n",
       " \n",
       "          [[ -43.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -66.]],\n",
       " \n",
       "          [[-122.]],\n",
       " \n",
       "          [[  34.]]]], device='cuda:0'),\n",
       " tensor([[[[  49.,  -98.,   55.],\n",
       "           [ -73.,  -21., -162.],\n",
       "           [  67., -170.,   85.]]],\n",
       " \n",
       " \n",
       "         [[[  17.,  -53.,   28.],\n",
       "           [  84., -153.,  102.],\n",
       "           [  16.,  -76.,   51.]]],\n",
       " \n",
       " \n",
       "         [[[  -2.,   40.,  -23.],\n",
       "           [  35.,  180.,   29.],\n",
       "           [ -26.,  229.,   60.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  -5.,   93.,  -63.],\n",
       "           [  69.,   80., -161.],\n",
       "           [ -53., -162., -139.]]],\n",
       " \n",
       " \n",
       "         [[[  21.,  -61.,   40.],\n",
       "           [ -11.,  194.,   12.],\n",
       "           [  15.,  -54.,   10.]]],\n",
       " \n",
       " \n",
       "         [[[ -49.,  -51.,  -36.],\n",
       "           [ -11., -105.,  150.],\n",
       "           [ -51.,  -61.,  -18.]]]], device='cuda:0'),\n",
       " tensor([[[[-23.]],\n",
       " \n",
       "          [[ 32.]],\n",
       " \n",
       "          [[ 80.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-45.]],\n",
       " \n",
       "          [[ -4.]],\n",
       " \n",
       "          [[ 16.]]],\n",
       " \n",
       " \n",
       "         [[[ 24.]],\n",
       " \n",
       "          [[-48.]],\n",
       " \n",
       "          [[ 41.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-13.]],\n",
       " \n",
       "          [[ 17.]],\n",
       " \n",
       "          [[ 33.]]],\n",
       " \n",
       " \n",
       "         [[[ 83.]],\n",
       " \n",
       "          [[-26.]],\n",
       " \n",
       "          [[ 53.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-30.]],\n",
       " \n",
       "          [[  1.]],\n",
       " \n",
       "          [[ -3.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-52.]],\n",
       " \n",
       "          [[  9.]],\n",
       " \n",
       "          [[-17.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 41.]],\n",
       " \n",
       "          [[-13.]],\n",
       " \n",
       "          [[-15.]]],\n",
       " \n",
       " \n",
       "         [[[ 50.]],\n",
       " \n",
       "          [[ 62.]],\n",
       " \n",
       "          [[ 31.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 44.]],\n",
       " \n",
       "          [[-15.]],\n",
       " \n",
       "          [[-19.]]],\n",
       " \n",
       " \n",
       "         [[[ 15.]],\n",
       " \n",
       "          [[-57.]],\n",
       " \n",
       "          [[ 19.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 42.]],\n",
       " \n",
       "          [[-56.]],\n",
       " \n",
       "          [[-19.]]]], device='cuda:0'),\n",
       " tensor([[[[  -7.]],\n",
       " \n",
       "          [[ -78.]],\n",
       " \n",
       "          [[  64.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[ -72.]]],\n",
       " \n",
       " \n",
       "         [[[ -94.]],\n",
       " \n",
       "          [[  46.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[ 141.]]],\n",
       " \n",
       " \n",
       "         [[[  98.]],\n",
       " \n",
       "          [[  66.]],\n",
       " \n",
       "          [[ -32.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-139.]],\n",
       " \n",
       "          [[ -82.]],\n",
       " \n",
       "          [[  46.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 144.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  83.]],\n",
       " \n",
       "          [[ -58.]],\n",
       " \n",
       "          [[ 116.]]],\n",
       " \n",
       " \n",
       "         [[[  66.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[-112.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -92.]],\n",
       " \n",
       "          [[  58.]],\n",
       " \n",
       "          [[  28.]]],\n",
       " \n",
       " \n",
       "         [[[ -68.]],\n",
       " \n",
       "          [[ -47.]],\n",
       " \n",
       "          [[ -57.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          [[  93.]],\n",
       " \n",
       "          [[ -41.]]]], device='cuda:0'),\n",
       " tensor([[[[ -21.,  -45.,  -29.],\n",
       "           [ -72., -257., -220.],\n",
       "           [ -56., -200., -276.]]],\n",
       " \n",
       " \n",
       "         [[[ -13.,  119.,  -43.],\n",
       "           [-136.,  109.,   47.],\n",
       "           [-120.,  -27.,   89.]]],\n",
       " \n",
       " \n",
       "         [[[-104., -228., -186.],\n",
       "           [-297., -359., -303.],\n",
       "           [-175., -328., -177.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  71.,  160.,   86.],\n",
       "           [ 117.,  291.,  200.],\n",
       "           [  36.,  162.,  142.]]],\n",
       " \n",
       " \n",
       "         [[[  72.,  187.,  148.],\n",
       "           [ 184.,  327.,  266.],\n",
       "           [ 142.,  255.,  203.]]],\n",
       " \n",
       " \n",
       "         [[[  15.,   73.,   12.],\n",
       "           [  94.,  267.,  125.],\n",
       "           [  36.,  130.,   70.]]]], device='cuda:0'),\n",
       " tensor([[[[-74.]],\n",
       " \n",
       "          [[ 50.]],\n",
       " \n",
       "          [[-18.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-57.]],\n",
       " \n",
       "          [[-23.]],\n",
       " \n",
       "          [[-67.]]],\n",
       " \n",
       " \n",
       "         [[[ 44.]],\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[-57.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-34.]],\n",
       " \n",
       "          [[ 61.]],\n",
       " \n",
       "          [[ 55.]]],\n",
       " \n",
       " \n",
       "         [[[ 99.]],\n",
       " \n",
       "          [[  3.]],\n",
       " \n",
       "          [[ 32.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 38.]],\n",
       " \n",
       "          [[-82.]],\n",
       " \n",
       "          [[-12.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-58.]],\n",
       " \n",
       "          [[-33.]],\n",
       " \n",
       "          [[ 89.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-19.]],\n",
       " \n",
       "          [[ 34.]],\n",
       " \n",
       "          [[ 21.]]],\n",
       " \n",
       " \n",
       "         [[[-13.]],\n",
       " \n",
       "          [[ -8.]],\n",
       " \n",
       "          [[ 14.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  6.]],\n",
       " \n",
       "          [[ 13.]],\n",
       " \n",
       "          [[-16.]]],\n",
       " \n",
       " \n",
       "         [[[ 23.]],\n",
       " \n",
       "          [[ 49.]],\n",
       " \n",
       "          [[  7.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 44.]],\n",
       " \n",
       "          [[ 64.]],\n",
       " \n",
       "          [[ -9.]]]], device='cuda:0'),\n",
       " tensor([[[[  14.]],\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          [[  34.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[ 167.]]],\n",
       " \n",
       " \n",
       "         [[[   4.]],\n",
       " \n",
       "          [[ -68.]],\n",
       " \n",
       "          [[  -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -66.]],\n",
       " \n",
       "          [[  63.]],\n",
       " \n",
       "          [[  46.]]],\n",
       " \n",
       " \n",
       "         [[[  30.]],\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  81.]],\n",
       " \n",
       "          [[  63.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -66.]],\n",
       " \n",
       "          [[ -22.]],\n",
       " \n",
       "          [[-132.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          [[  75.]]],\n",
       " \n",
       " \n",
       "         [[[  24.]],\n",
       " \n",
       "          [[  70.]],\n",
       " \n",
       "          [[  80.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  94.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[  37.]]],\n",
       " \n",
       " \n",
       "         [[[  80.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          [[-100.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 145.]],\n",
       " \n",
       "          [[ -84.]],\n",
       " \n",
       "          [[ -82.]]]], device='cuda:0'),\n",
       " tensor([[[[  27.,   27.,   10.],\n",
       "           [  35., -208.,   47.],\n",
       "           [  -1.,   29.,   32.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.,  109.,   46.],\n",
       "           [  63.,  122.,  -14.],\n",
       "           [ -23., -133., -100.]]],\n",
       " \n",
       " \n",
       "         [[[  99.,  101.,   13.],\n",
       "           [  94., -118., -133.],\n",
       "           [  61., -154.,   -3.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -10.,  -78.,   -4.],\n",
       "           [ -74.,  177.,  -60.],\n",
       "           [ -20.,  -71.,   -9.]]],\n",
       " \n",
       " \n",
       "         [[[  10.,   -0.,    9.],\n",
       "           [ -10.,  143.,  -35.],\n",
       "           [  -2., -112.,   -8.]]],\n",
       " \n",
       " \n",
       "         [[[ -80.,   66.,    7.],\n",
       "           [-132.,   42.,  123.],\n",
       "           [  -4.,  -40.,   25.]]]], device='cuda:0'),\n",
       " tensor([[[[ -76.]],\n",
       " \n",
       "          [[  80.]],\n",
       " \n",
       "          [[  -8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -28.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[  23.]]],\n",
       " \n",
       " \n",
       "         [[[  65.]],\n",
       " \n",
       "          [[  29.]],\n",
       " \n",
       "          [[  -0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[  54.]]],\n",
       " \n",
       " \n",
       "         [[[  23.]],\n",
       " \n",
       "          [[  42.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[ -73.]],\n",
       " \n",
       "          [[  16.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -80.]],\n",
       " \n",
       "          [[  48.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[  70.]],\n",
       " \n",
       "          [[ -15.]]],\n",
       " \n",
       " \n",
       "         [[[  -8.]],\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -73.]],\n",
       " \n",
       "          [[ -24.]],\n",
       " \n",
       "          [[  60.]]],\n",
       " \n",
       " \n",
       "         [[[-107.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[ -68.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[ 103.]]]], device='cuda:0'),\n",
       " tensor([[[[-104.]],\n",
       " \n",
       "          [[ -73.]],\n",
       " \n",
       "          [[  23.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[  91.]],\n",
       " \n",
       "          [[ -41.]]],\n",
       " \n",
       " \n",
       "         [[[  -1.]],\n",
       " \n",
       "          [[ -72.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[  75.]],\n",
       " \n",
       "          [[ -10.]]],\n",
       " \n",
       " \n",
       "         [[[  24.]],\n",
       " \n",
       "          [[ -63.]],\n",
       " \n",
       "          [[ 105.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -46.]],\n",
       " \n",
       "          [[-109.]],\n",
       " \n",
       "          [[ -67.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -45.]],\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-169.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[  27.]]],\n",
       " \n",
       " \n",
       "         [[[ -97.]],\n",
       " \n",
       "          [[ 137.]],\n",
       " \n",
       "          [[ -48.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  46.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[  30.]]],\n",
       " \n",
       " \n",
       "         [[[  16.]],\n",
       " \n",
       "          [[ 113.]],\n",
       " \n",
       "          [[-115.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -54.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[ -66.]]]], device='cuda:0'),\n",
       " tensor([[[[ -13.,    1.,   21.],\n",
       "           [  33., -130.,  -75.],\n",
       "           [  -4.,  125.,   55.]]],\n",
       " \n",
       " \n",
       "         [[[  45.,  154.,   57.],\n",
       "           [-101.,  -65.,  -72.],\n",
       "           [   9.,  -41.,    8.]]],\n",
       " \n",
       " \n",
       "         [[[  25.,  198.,    3.],\n",
       "           [ 192.,  196.,  195.],\n",
       "           [ -57.,  174.,   14.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -13.,   89.,  -18.],\n",
       "           [-117.,   24.,  137.],\n",
       "           [ -14., -118.,    1.]]],\n",
       " \n",
       " \n",
       "         [[[   6.,   -5.,   11.],\n",
       "           [   0.,  234.,   17.],\n",
       "           [ -21.,   22.,    8.]]],\n",
       " \n",
       " \n",
       "         [[[ -21., -119.,   41.],\n",
       "           [-134.,   -7.,  102.],\n",
       "           [ -14.,  121.,  -94.]]]], device='cuda:0'),\n",
       " tensor([[[[ -36.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[ -42.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[ -12.]]],\n",
       " \n",
       " \n",
       "         [[[ -50.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[  63.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[ -34.]],\n",
       " \n",
       "          [[   8.]]],\n",
       " \n",
       " \n",
       "         [[[ -11.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[ -73.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  36.]],\n",
       " \n",
       "          [[ -46.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[   9.]],\n",
       " \n",
       "          [[  23.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -13.]],\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[ -43.]]],\n",
       " \n",
       " \n",
       "         [[[ -21.]],\n",
       " \n",
       "          [[ -22.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-106.]],\n",
       " \n",
       "          [[ -59.]],\n",
       " \n",
       "          [[  30.]]],\n",
       " \n",
       " \n",
       "         [[[  48.]],\n",
       " \n",
       "          [[ -41.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[ -35.]]]], device='cuda:0'),\n",
       " tensor([[[[ -5.]],\n",
       " \n",
       "          [[149.]],\n",
       " \n",
       "          [[ 41.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 32.]],\n",
       " \n",
       "          [[-26.]],\n",
       " \n",
       "          [[ 29.]]],\n",
       " \n",
       " \n",
       "         [[[ 20.]],\n",
       " \n",
       "          [[ 44.]],\n",
       " \n",
       "          [[ 23.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-19.]],\n",
       " \n",
       "          [[ -0.]],\n",
       " \n",
       "          [[-41.]]],\n",
       " \n",
       " \n",
       "         [[[  5.]],\n",
       " \n",
       "          [[-51.]],\n",
       " \n",
       "          [[ 83.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-32.]],\n",
       " \n",
       "          [[ 29.]],\n",
       " \n",
       "          [[106.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 31.]],\n",
       " \n",
       "          [[ 14.]],\n",
       " \n",
       "          [[-32.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-67.]],\n",
       " \n",
       "          [[-31.]],\n",
       " \n",
       "          [[-11.]]],\n",
       " \n",
       " \n",
       "         [[[-41.]],\n",
       " \n",
       "          [[ 66.]],\n",
       " \n",
       "          [[-42.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 90.]],\n",
       " \n",
       "          [[-46.]],\n",
       " \n",
       "          [[-63.]]],\n",
       " \n",
       " \n",
       "         [[[ 76.]],\n",
       " \n",
       "          [[  2.]],\n",
       " \n",
       "          [[-42.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 94.]],\n",
       " \n",
       "          [[-47.]],\n",
       " \n",
       "          [[ 62.]]]], device='cuda:0'),\n",
       " tensor([[[[ 144.,  187.,  170.],\n",
       "           [ 225.,  399.,  338.],\n",
       "           [ 182.,  338.,  221.]]],\n",
       " \n",
       " \n",
       "         [[[ -85., -117., -129.],\n",
       "           [-176., -340., -276.],\n",
       "           [-111., -219., -244.]]],\n",
       " \n",
       " \n",
       "         [[[ -72., -171.,  -82.],\n",
       "           [-170., -312., -111.],\n",
       "           [-137., -189.,  -57.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  93.,  164.,  102.],\n",
       "           [ 158.,  348.,  226.],\n",
       "           [ 106.,  226.,  124.]]],\n",
       " \n",
       " \n",
       "         [[[ -54., -151., -103.],\n",
       "           [-110., -303., -228.],\n",
       "           [ -48., -204., -140.]]],\n",
       " \n",
       " \n",
       "         [[[ 150.,  269.,  228.],\n",
       "           [ 234.,  396.,  330.],\n",
       "           [ 141.,  259.,  236.]]]], device='cuda:0'),\n",
       " tensor([[[[  49.]],\n",
       " \n",
       "          [[ -60.]],\n",
       " \n",
       "          [[  75.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  15.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          [[  92.]]],\n",
       " \n",
       " \n",
       "         [[[ -26.]],\n",
       " \n",
       "          [[  26.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  33.]],\n",
       " \n",
       "          [[  64.]],\n",
       " \n",
       "          [[  21.]]],\n",
       " \n",
       " \n",
       "         [[[  73.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[ -30.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 100.]],\n",
       " \n",
       "          [[  -2.]],\n",
       " \n",
       "          [[  68.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  21.]],\n",
       " \n",
       "          [[  64.]],\n",
       " \n",
       "          [[  75.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[ -23.]],\n",
       " \n",
       "          [[ -44.]]],\n",
       " \n",
       " \n",
       "         [[[-102.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          [[ -36.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[ -35.]]],\n",
       " \n",
       " \n",
       "         [[[ -32.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[ -45.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[ 139.]],\n",
       " \n",
       "          [[ -31.]]]], device='cuda:0'),\n",
       " tensor([[[[ -11.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[  50.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -69.]],\n",
       " \n",
       "          [[ -50.]],\n",
       " \n",
       "          [[ 127.]]],\n",
       " \n",
       " \n",
       "         [[[ -26.]],\n",
       " \n",
       "          [[ -39.]],\n",
       " \n",
       "          [[ 124.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[ 105.]]],\n",
       " \n",
       " \n",
       "         [[[  57.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[ -82.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  99.]],\n",
       " \n",
       "          [[ -49.]],\n",
       " \n",
       "          [[  31.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -50.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[  86.]],\n",
       " \n",
       "          [[  37.]]],\n",
       " \n",
       " \n",
       "         [[[  50.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[ -42.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  87.]],\n",
       " \n",
       "          [[ -58.]],\n",
       " \n",
       "          [[  11.]]],\n",
       " \n",
       " \n",
       "         [[[  72.]],\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -24.]],\n",
       " \n",
       "          [[ -22.]],\n",
       " \n",
       "          [[-119.]]]], device='cuda:0'),\n",
       " tensor([[[[ -38.,  -72.,  -52.],\n",
       "           [  23.,  179.,   21.],\n",
       "           [ -14.,  -76.,  -41.]]],\n",
       " \n",
       " \n",
       "         [[[-113.,   72.,    4.],\n",
       "           [-103.,  136.,   36.],\n",
       "           [-119.,  117.,  -27.]]],\n",
       " \n",
       " \n",
       "         [[[  -7.,   10.,    8.],\n",
       "           [ 145.,  -48., -110.],\n",
       "           [  21.,   -3.,  -18.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -15., -110.,  -92.],\n",
       "           [  88.,    3., -121.],\n",
       "           [  43.,  134.,   16.]]],\n",
       " \n",
       " \n",
       "         [[[ -43.,  -51.,  -17.],\n",
       "           [ -44.,  200.,  -45.],\n",
       "           [ -55.,  -36.,  -40.]]],\n",
       " \n",
       " \n",
       "         [[[ -11., -163.,  -72.],\n",
       "           [ -61., -266.,  -58.],\n",
       "           [ -87., -230.,  -27.]]]], device='cuda:0'),\n",
       " tensor([[[[-27.]],\n",
       " \n",
       "          [[ 19.]],\n",
       " \n",
       "          [[-19.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 76.]],\n",
       " \n",
       "          [[-24.]],\n",
       " \n",
       "          [[-70.]]],\n",
       " \n",
       " \n",
       "         [[[  2.]],\n",
       " \n",
       "          [[-20.]],\n",
       " \n",
       "          [[  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  7.]],\n",
       " \n",
       "          [[ 27.]],\n",
       " \n",
       "          [[ 31.]]],\n",
       " \n",
       " \n",
       "         [[[ 65.]],\n",
       " \n",
       "          [[ 24.]],\n",
       " \n",
       "          [[  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 25.]],\n",
       " \n",
       "          [[-29.]],\n",
       " \n",
       "          [[-11.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -8.]],\n",
       " \n",
       "          [[-29.]],\n",
       " \n",
       "          [[-33.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 23.]],\n",
       " \n",
       "          [[ 53.]],\n",
       " \n",
       "          [[ 62.]]],\n",
       " \n",
       " \n",
       "         [[[-28.]],\n",
       " \n",
       "          [[  2.]],\n",
       " \n",
       "          [[ -4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -4.]],\n",
       " \n",
       "          [[ 44.]],\n",
       " \n",
       "          [[ 68.]]],\n",
       " \n",
       " \n",
       "         [[[ 80.]],\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[ 11.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 52.]],\n",
       " \n",
       "          [[ 24.]],\n",
       " \n",
       "          [[-32.]]]], device='cuda:0'),\n",
       " tensor([[[[  22.]],\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          [[ -55.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          [[ -48.]]],\n",
       " \n",
       " \n",
       "         [[[  22.]],\n",
       " \n",
       "          [[ -94.]],\n",
       " \n",
       "          [[  43.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  59.]],\n",
       " \n",
       "          [[ -80.]]],\n",
       " \n",
       " \n",
       "         [[[  18.]],\n",
       " \n",
       "          [[ -15.]],\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[  95.]],\n",
       " \n",
       "          [[   1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  -2.]],\n",
       " \n",
       "          [[ -14.]],\n",
       " \n",
       "          [[-118.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 108.]],\n",
       " \n",
       "          [[  58.]],\n",
       " \n",
       "          [[-112.]]],\n",
       " \n",
       " \n",
       "         [[[-133.]],\n",
       " \n",
       "          [[ -46.]],\n",
       " \n",
       "          [[ -35.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          [[  39.]]],\n",
       " \n",
       " \n",
       "         [[[ -73.]],\n",
       " \n",
       "          [[ -32.]],\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[  -8.]],\n",
       " \n",
       "          [[ -45.]]]], device='cuda:0'),\n",
       " tensor([[[[   7.,  -27.,   -6.],\n",
       "           [  -9.,  119.,    8.],\n",
       "           [ -45., -136.,  -21.]]],\n",
       " \n",
       " \n",
       "         [[[   1.,   -8.,   29.],\n",
       "           [ -54., -113.,  142.],\n",
       "           [ -15.,   -3.,   18.]]],\n",
       " \n",
       " \n",
       "         [[[ 112.,   85.,   23.],\n",
       "           [  29., -143.,  -61.],\n",
       "           [  -0.,  -51.,  -18.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  25.,   27.,   56.],\n",
       "           [  26.,  248.,   -7.],\n",
       "           [  44.,   96.,   50.]]],\n",
       " \n",
       " \n",
       "         [[[  27.,  -26.,   95.],\n",
       "           [ 212.,  -43.,  180.],\n",
       "           [  62.,  -24.,   35.]]],\n",
       " \n",
       " \n",
       "         [[[  49.,  175.,   64.],\n",
       "           [ -19.,  -80.,  -17.],\n",
       "           [  10.,  -36.,   -1.]]]], device='cuda:0'),\n",
       " tensor([[[[  96.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -56.]],\n",
       " \n",
       "          [[ -48.]],\n",
       " \n",
       "          [[   5.]]],\n",
       " \n",
       " \n",
       "         [[[ -14.]],\n",
       " \n",
       "          [[ -53.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -39.]],\n",
       " \n",
       "          [[ -42.]],\n",
       " \n",
       "          [[ -27.]]],\n",
       " \n",
       " \n",
       "         [[[  35.]],\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[  54.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -22.]],\n",
       " \n",
       "          [[ -68.]],\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[-134.]],\n",
       " \n",
       "          [[  27.]]],\n",
       " \n",
       " \n",
       "         [[[  75.]],\n",
       " \n",
       "          [[  25.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[ -39.]],\n",
       " \n",
       "          [[ -40.]]],\n",
       " \n",
       " \n",
       "         [[[  71.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -27.]],\n",
       " \n",
       "          [[  71.]],\n",
       " \n",
       "          [[  70.]]]], device='cuda:0'),\n",
       " tensor([[[[-107.]],\n",
       " \n",
       "          [[  51.]],\n",
       " \n",
       "          [[ -83.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  45.]],\n",
       " \n",
       "          [[ -28.]],\n",
       " \n",
       "          [[  71.]]],\n",
       " \n",
       " \n",
       "         [[[ -55.]],\n",
       " \n",
       "          [[  37.]],\n",
       " \n",
       "          [[  -9.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  17.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[  -1.]]],\n",
       " \n",
       " \n",
       "         [[[  58.]],\n",
       " \n",
       "          [[  14.]],\n",
       " \n",
       "          [[  40.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  83.]],\n",
       " \n",
       "          [[  78.]],\n",
       " \n",
       "          [[ -47.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -75.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  49.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  36.]],\n",
       " \n",
       "          [[  53.]]],\n",
       " \n",
       " \n",
       "         [[[  -6.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          [[ -47.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[  33.]],\n",
       " \n",
       "          [[ -39.]]],\n",
       " \n",
       " \n",
       "         [[[  12.]],\n",
       " \n",
       "          [[ -25.]],\n",
       " \n",
       "          [[  20.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 125.]],\n",
       " \n",
       "          [[  -5.]],\n",
       " \n",
       "          [[  39.]]]], device='cuda:0'),\n",
       " tensor([[[[ -57.,   28.,   61.],\n",
       "           [ -32.,  -96.,  159.],\n",
       "           [   7.,   51.,   67.]]],\n",
       " \n",
       " \n",
       "         [[[   8.,    6.,    1.],\n",
       "           [  44.,  228.,   35.],\n",
       "           [  46.,  -27.,   37.]]],\n",
       " \n",
       " \n",
       "         [[[  34.,  -14., -125.],\n",
       "           [ 130.,   44.,  -29.],\n",
       "           [  63.,   34.,  -40.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -10.,  -27.,  -14.],\n",
       "           [ -43., -113.,  -30.],\n",
       "           [  15.,  142.,   12.]]],\n",
       " \n",
       " \n",
       "         [[[  33.,  -25.,  -10.],\n",
       "           [  63.,  -83.,  -28.],\n",
       "           [ 172.,   41.,  -28.]]],\n",
       " \n",
       " \n",
       "         [[[  -5.,   19.,  -25.],\n",
       "           [ -48.,  140.,   48.],\n",
       "           [ -85., -115.,  -14.]]]], device='cuda:0'),\n",
       " tensor([[[[  9.]],\n",
       " \n",
       "          [[-64.]],\n",
       " \n",
       "          [[-35.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-24.]],\n",
       " \n",
       "          [[-70.]],\n",
       " \n",
       "          [[ 66.]]],\n",
       " \n",
       " \n",
       "         [[[ -6.]],\n",
       " \n",
       "          [[ 17.]],\n",
       " \n",
       "          [[ 35.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  6.]],\n",
       " \n",
       "          [[ 65.]],\n",
       " \n",
       "          [[ 15.]]],\n",
       " \n",
       " \n",
       "         [[[ -1.]],\n",
       " \n",
       "          [[-31.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 31.]],\n",
       " \n",
       "          [[ 18.]],\n",
       " \n",
       "          [[  0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  9.]],\n",
       " \n",
       "          [[ 35.]],\n",
       " \n",
       "          [[ 30.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -5.]],\n",
       " \n",
       "          [[ 31.]],\n",
       " \n",
       "          [[-96.]]],\n",
       " \n",
       " \n",
       "         [[[  5.]],\n",
       " \n",
       "          [[-52.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[ 40.]],\n",
       " \n",
       "          [[ 16.]]],\n",
       " \n",
       " \n",
       "         [[[-10.]],\n",
       " \n",
       "          [[ 53.]],\n",
       " \n",
       "          [[ 57.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 51.]],\n",
       " \n",
       "          [[ 21.]],\n",
       " \n",
       "          [[  4.]]]], device='cuda:0'),\n",
       " tensor([[[[  88.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          [[  56.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -76.]],\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          [[  46.]]],\n",
       " \n",
       " \n",
       "         [[[  45.]],\n",
       " \n",
       "          [[ -91.]],\n",
       " \n",
       "          [[  24.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          [[ -52.]],\n",
       " \n",
       "          [[ -62.]]],\n",
       " \n",
       " \n",
       "         [[[  30.]],\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          [[ -26.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[ -87.]],\n",
       " \n",
       "          [[  21.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-146.]],\n",
       " \n",
       "          [[  87.]],\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   3.]],\n",
       " \n",
       "          [[ -66.]],\n",
       " \n",
       "          [[  33.]]],\n",
       " \n",
       " \n",
       "         [[[  -0.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[ -43.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -87.]],\n",
       " \n",
       "          [[ -44.]],\n",
       " \n",
       "          [[ -54.]]],\n",
       " \n",
       " \n",
       "         [[[  39.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[ -27.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          [[ -65.]],\n",
       " \n",
       "          [[ -92.]]]], device='cuda:0'),\n",
       " tensor([[[[   5.,    4.,  -44.],\n",
       "           [  95.,   81., -160.],\n",
       "           [  -9.,   -9.,  -71.]]],\n",
       " \n",
       " \n",
       "         [[[  23.,  147.,   56.],\n",
       "           [   8., -108.,  -12.],\n",
       "           [  -4.,  -22.,  -19.]]],\n",
       " \n",
       " \n",
       "         [[[ -15.,    1.,  -13.],\n",
       "           [  33.,  223.,  110.],\n",
       "           [ -32.,   88.,   22.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  19.,   18.,  -22.],\n",
       "           [  12.,  233.,    6.],\n",
       "           [   3.,   32.,   54.]]],\n",
       " \n",
       " \n",
       "         [[[-160.,  -80., -188.],\n",
       "           [  18., -190.,  -66.],\n",
       "           [-237., -100., -216.]]],\n",
       " \n",
       " \n",
       "         [[[   1.,  -23.,   86.],\n",
       "           [ -94.,   13.,  161.],\n",
       "           [  -5.,  -63.,   -4.]]]], device='cuda:0'),\n",
       " tensor([[[[-33.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          [[ 12.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-33.]],\n",
       " \n",
       "          [[-34.]],\n",
       " \n",
       "          [[-13.]]],\n",
       " \n",
       " \n",
       "         [[[ 18.]],\n",
       " \n",
       "          [[ 25.]],\n",
       " \n",
       "          [[ 11.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  4.]],\n",
       " \n",
       "          [[ 91.]],\n",
       " \n",
       "          [[  5.]]],\n",
       " \n",
       " \n",
       "         [[[ 26.]],\n",
       " \n",
       "          [[-50.]],\n",
       " \n",
       "          [[ 71.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 99.]],\n",
       " \n",
       "          [[-23.]],\n",
       " \n",
       "          [[-44.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 15.]],\n",
       " \n",
       "          [[ 34.]],\n",
       " \n",
       "          [[-96.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-13.]],\n",
       " \n",
       "          [[ 12.]],\n",
       " \n",
       "          [[-76.]]],\n",
       " \n",
       " \n",
       "         [[[-12.]],\n",
       " \n",
       "          [[-25.]],\n",
       " \n",
       "          [[ -6.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-17.]],\n",
       " \n",
       "          [[-67.]],\n",
       " \n",
       "          [[-46.]]],\n",
       " \n",
       " \n",
       "         [[[-15.]],\n",
       " \n",
       "          [[ 36.]],\n",
       " \n",
       "          [[-28.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  4.]],\n",
       " \n",
       "          [[-43.]],\n",
       " \n",
       "          [[ 54.]]]], device='cuda:0'),\n",
       " tensor([[[[-28.]],\n",
       " \n",
       "          [[-57.]],\n",
       " \n",
       "          [[-20.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-35.]],\n",
       " \n",
       "          [[-75.]],\n",
       " \n",
       "          [[-67.]]],\n",
       " \n",
       " \n",
       "         [[[-41.]],\n",
       " \n",
       "          [[  6.]],\n",
       " \n",
       "          [[ 36.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 28.]],\n",
       " \n",
       "          [[ 17.]],\n",
       " \n",
       "          [[-39.]]],\n",
       " \n",
       " \n",
       "         [[[-55.]],\n",
       " \n",
       "          [[-37.]],\n",
       " \n",
       "          [[-20.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  7.]],\n",
       " \n",
       "          [[ -1.]],\n",
       " \n",
       "          [[ -1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 40.]],\n",
       " \n",
       "          [[-10.]],\n",
       " \n",
       "          [[-54.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-17.]],\n",
       " \n",
       "          [[ 72.]],\n",
       " \n",
       "          [[ 16.]]],\n",
       " \n",
       " \n",
       "         [[[ 53.]],\n",
       " \n",
       "          [[ 58.]],\n",
       " \n",
       "          [[  4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-81.]],\n",
       " \n",
       "          [[-68.]],\n",
       " \n",
       "          [[ 23.]]],\n",
       " \n",
       " \n",
       "         [[[ -5.]],\n",
       " \n",
       "          [[-29.]],\n",
       " \n",
       "          [[ -3.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 66.]],\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[-52.]]]], device='cuda:0'),\n",
       " tensor([[[[ -61., -111.,  -54.],\n",
       "           [ -55.,  144.,  -53.],\n",
       "           [ -67.,  -48.,  -29.]]],\n",
       " \n",
       " \n",
       "         [[[  32.,   44.,   32.],\n",
       "           [  24.,  279.,   47.],\n",
       "           [  25.,   32.,   36.]]],\n",
       " \n",
       " \n",
       "         [[[ -64.,   17.,   69.],\n",
       "           [-127.,   18.,  128.],\n",
       "           [  47.,  -16.,  -24.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[  94.,    6.,  101.],\n",
       "           [  53.,  261.,   89.],\n",
       "           [  85.,   81.,  111.]]],\n",
       " \n",
       " \n",
       "         [[[ 241.,  239.,  209.],\n",
       "           [ 395.,  449.,  464.],\n",
       "           [ 225.,  301.,  280.]]],\n",
       " \n",
       " \n",
       "         [[[ 116.,   58.,  -22.],\n",
       "           [ 102.,  224.,  -31.],\n",
       "           [  34.,   65.,   17.]]]], device='cuda:0'),\n",
       " tensor([[[[  5.]],\n",
       " \n",
       "          [[-86.]],\n",
       " \n",
       "          [[ 39.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-39.]],\n",
       " \n",
       "          [[ -1.]],\n",
       " \n",
       "          [[-59.]]],\n",
       " \n",
       " \n",
       "         [[[ 71.]],\n",
       " \n",
       "          [[-33.]],\n",
       " \n",
       "          [[  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[-65.]],\n",
       " \n",
       "          [[ -9.]]],\n",
       " \n",
       " \n",
       "         [[[ 42.]],\n",
       " \n",
       "          [[ 46.]],\n",
       " \n",
       "          [[-33.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 36.]],\n",
       " \n",
       "          [[-32.]],\n",
       " \n",
       "          [[ 22.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-54.]],\n",
       " \n",
       "          [[-27.]],\n",
       " \n",
       "          [[ 18.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 77.]],\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[-21.]]],\n",
       " \n",
       " \n",
       "         [[[-20.]],\n",
       " \n",
       "          [[-37.]],\n",
       " \n",
       "          [[-22.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          [[ 14.]],\n",
       " \n",
       "          [[ 14.]]],\n",
       " \n",
       " \n",
       "         [[[ 37.]],\n",
       " \n",
       "          [[-73.]],\n",
       " \n",
       "          [[  6.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-20.]],\n",
       " \n",
       "          [[-50.]],\n",
       " \n",
       "          [[ -5.]]]], device='cuda:0'),\n",
       " tensor([[[[-37.]],\n",
       " \n",
       "          [[ 86.]],\n",
       " \n",
       "          [[-53.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 16.]],\n",
       " \n",
       "          [[  5.]],\n",
       " \n",
       "          [[-39.]]],\n",
       " \n",
       " \n",
       "         [[[-18.]],\n",
       " \n",
       "          [[ 16.]],\n",
       " \n",
       "          [[-26.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-28.]],\n",
       " \n",
       "          [[-46.]],\n",
       " \n",
       "          [[ 13.]]],\n",
       " \n",
       " \n",
       "         [[[ 18.]],\n",
       " \n",
       "          [[ 10.]],\n",
       " \n",
       "          [[ 24.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -0.]],\n",
       " \n",
       "          [[  9.]],\n",
       " \n",
       "          [[-20.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 63.]],\n",
       " \n",
       "          [[ 51.]],\n",
       " \n",
       "          [[-78.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 53.]],\n",
       " \n",
       "          [[-10.]],\n",
       " \n",
       "          [[-56.]]],\n",
       " \n",
       " \n",
       "         [[[ 51.]],\n",
       " \n",
       "          [[ 16.]],\n",
       " \n",
       "          [[ 61.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 26.]],\n",
       " \n",
       "          [[-35.]],\n",
       " \n",
       "          [[-13.]]],\n",
       " \n",
       " \n",
       "         [[[ 11.]],\n",
       " \n",
       "          [[-44.]],\n",
       " \n",
       "          [[ 71.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 14.]],\n",
       " \n",
       "          [[ 32.]],\n",
       " \n",
       "          [[-48.]]]], device='cuda:0'),\n",
       " tensor([[[[-268., -176., -249.],\n",
       "           [-371., -358., -292.],\n",
       "           [-120., -116., -306.]]],\n",
       " \n",
       " \n",
       "         [[[  81.,   50.,   82.],\n",
       "           [  38., -173.,   32.],\n",
       "           [ -31.,  -19.,  -31.]]],\n",
       " \n",
       " \n",
       "         [[[ -22.,   45.,  -20.],\n",
       "           [  45.,  229.,   67.],\n",
       "           [ -26.,   80.,  -24.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-362., -248., -399.],\n",
       "           [-198., -453., -204.],\n",
       "           [-415., -398., -430.]]],\n",
       " \n",
       " \n",
       "         [[[  -9.,   12.,  -14.],\n",
       "           [  22.,  241.,   16.],\n",
       "           [  16.,  137.,   17.]]],\n",
       " \n",
       " \n",
       "         [[[ 161.,  102.,  138.],\n",
       "           [ 160.,  116.,  251.],\n",
       "           [  31.,  286.,  141.]]]], device='cuda:0'),\n",
       " tensor([[[[ -52.]],\n",
       " \n",
       "          [[  58.]],\n",
       " \n",
       "          [[-115.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -20.]],\n",
       " \n",
       "          [[ -66.]],\n",
       " \n",
       "          [[   9.]]],\n",
       " \n",
       " \n",
       "         [[[  15.]],\n",
       " \n",
       "          [[  34.]],\n",
       " \n",
       "          [[   7.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[  34.]],\n",
       " \n",
       "          [[   7.]]],\n",
       " \n",
       " \n",
       "         [[[  11.]],\n",
       " \n",
       "          [[  21.]],\n",
       " \n",
       "          [[   5.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  53.]],\n",
       " \n",
       "          [[  -6.]],\n",
       " \n",
       "          [[  -3.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -30.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          [[  56.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[ -34.]]],\n",
       " \n",
       " \n",
       "         [[[  -9.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -29.]],\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[ -19.]]],\n",
       " \n",
       " \n",
       "         [[[ -24.]],\n",
       " \n",
       "          [[  49.]],\n",
       " \n",
       "          [[ 130.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   1.]],\n",
       " \n",
       "          [[  59.]],\n",
       " \n",
       "          [[  30.]]]], device='cuda:0'),\n",
       " tensor([[[[  31.]],\n",
       " \n",
       "          [[  51.]],\n",
       " \n",
       "          [[ -39.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  67.]],\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[ -48.]]],\n",
       " \n",
       " \n",
       "         [[[ -15.]],\n",
       " \n",
       "          [[  67.]],\n",
       " \n",
       "          [[  -6.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[  19.]]],\n",
       " \n",
       " \n",
       "         [[[  46.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[  44.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  71.]],\n",
       " \n",
       "          [[  50.]],\n",
       " \n",
       "          [[  16.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-140.]],\n",
       " \n",
       "          [[ -29.]],\n",
       " \n",
       "          [[  28.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  41.]],\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[  -4.]]],\n",
       " \n",
       " \n",
       "         [[[  22.]],\n",
       " \n",
       "          [[  47.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          [[  39.]],\n",
       " \n",
       "          [[ -75.]]],\n",
       " \n",
       " \n",
       "         [[[ -16.]],\n",
       " \n",
       "          [[ 103.]],\n",
       " \n",
       "          [[ -64.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          [[  65.]],\n",
       " \n",
       "          [[  -8.]]]], device='cuda:0'),\n",
       " tensor([[[[ -58., -186., -149.],\n",
       "           [-219., -224., -313.],\n",
       "           [-231., -293., -303.]]],\n",
       " \n",
       " \n",
       "         [[[ -71., -249., -173.],\n",
       "           [-268., -326., -316.],\n",
       "           [-181., -290., -202.]]],\n",
       " \n",
       " \n",
       "         [[[  90.,  185.,  152.],\n",
       "           [ 171.,  345.,  252.],\n",
       "           [  94.,  227.,  189.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-116., -202., -253.],\n",
       "           [-234., -371., -298.],\n",
       "           [-150., -355., -294.]]],\n",
       " \n",
       " \n",
       "         [[[  86.,  186.,  130.],\n",
       "           [ 169.,  341.,  260.],\n",
       "           [ 101.,  255.,  186.]]],\n",
       " \n",
       " \n",
       "         [[[-261., -484., -273.],\n",
       "           [-418., -443., -443.],\n",
       "           [-352., -516., -426.]]]], device='cuda:0'),\n",
       " tensor([[[[  -5.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          [[ -33.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -18.]],\n",
       " \n",
       "          [[  48.]],\n",
       " \n",
       "          [[ -33.]]],\n",
       " \n",
       " \n",
       "         [[[ -14.]],\n",
       " \n",
       "          [[  35.]],\n",
       " \n",
       "          [[ -27.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  67.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[  19.]]],\n",
       " \n",
       " \n",
       "         [[[ -30.]],\n",
       " \n",
       "          [[-110.]],\n",
       " \n",
       "          [[ -32.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  -3.]],\n",
       " \n",
       "          [[ -38.]],\n",
       " \n",
       "          [[  30.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -42.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          [[  65.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  69.]],\n",
       " \n",
       "          [[ -20.]],\n",
       " \n",
       "          [[  62.]]],\n",
       " \n",
       " \n",
       "         [[[  23.]],\n",
       " \n",
       "          [[  12.]],\n",
       " \n",
       "          [[  15.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -44.]],\n",
       " \n",
       "          [[ -17.]],\n",
       " \n",
       "          [[   0.]]],\n",
       " \n",
       " \n",
       "         [[[  -6.]],\n",
       " \n",
       "          [[ -16.]],\n",
       " \n",
       "          [[  81.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          [[ -69.]],\n",
       " \n",
       "          [[  43.]]]], device='cuda:0'),\n",
       " tensor([[[[ 2.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[ 1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[ 2.]]],\n",
       " \n",
       " \n",
       "         [[[ 2.]],\n",
       " \n",
       "          [[ 0.]],\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[-2.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[ 4.]],\n",
       " \n",
       "          [[ 1.]]],\n",
       " \n",
       " \n",
       "         [[[ 2.]],\n",
       " \n",
       "          [[ 5.]],\n",
       " \n",
       "          [[ 5.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-0.]]],\n",
       " \n",
       " \n",
       "         [[[ 3.]],\n",
       " \n",
       "          [[ 5.]],\n",
       " \n",
       "          [[ 8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.]],\n",
       " \n",
       "          [[-6.]],\n",
       " \n",
       "          [[ 0.]]]], device='cuda:0'),\n",
       " tensor([[[[   8.,   79.,   35.],\n",
       "           [  67.,  263.,   84.],\n",
       "           [  35.,   30.,   76.]]],\n",
       " \n",
       " \n",
       "         [[[ -52.,   37.,  -66.],\n",
       "           [ -64.,  189.,   42.],\n",
       "           [  31.,  153.,   48.]]],\n",
       " \n",
       " \n",
       "         [[[ -38.,   30.,  -34.],\n",
       "           [ -58., -148.,  -58.],\n",
       "           [  90.,  107.,   91.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -81., -293., -161.],\n",
       "           [-325., -336., -226.],\n",
       "           [-178., -150., -181.]]],\n",
       " \n",
       " \n",
       "         [[[ -28.,  138., -117.],\n",
       "           [  15.,  -50.,   54.],\n",
       "           [  11.,  -54.,   45.]]],\n",
       " \n",
       " \n",
       "         [[[  50.,  150.,   64.],\n",
       "           [ -28.,   44.,  -39.],\n",
       "           [ -84., -105.,  -86.]]]], device='cuda:0'),\n",
       " tensor([[[[-2.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[ 3.]]],\n",
       " \n",
       " \n",
       "         [[[ 4.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[ 2.]]],\n",
       " \n",
       " \n",
       "         [[[-4.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-6.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[ 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-1.]]],\n",
       " \n",
       " \n",
       "         [[[ 2.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-3.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[-1.]]]], device='cuda:0'),\n",
       " tensor([[[[-102.]],\n",
       " \n",
       "          [[ 107.]],\n",
       " \n",
       "          [[  -7.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[ -59.]]],\n",
       " \n",
       " \n",
       "         [[[  -3.]],\n",
       " \n",
       "          [[ -10.]],\n",
       " \n",
       "          [[   9.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -11.]],\n",
       " \n",
       "          [[   4.]],\n",
       " \n",
       "          [[  -5.]]],\n",
       " \n",
       " \n",
       "         [[[ -61.]],\n",
       " \n",
       "          [[   2.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  23.]],\n",
       " \n",
       "          [[ -35.]],\n",
       " \n",
       "          [[  -7.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -72.]],\n",
       " \n",
       "          [[  26.]],\n",
       " \n",
       "          [[  80.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  -6.]],\n",
       " \n",
       "          [[ -50.]],\n",
       " \n",
       "          [[  -8.]]],\n",
       " \n",
       " \n",
       "         [[[ -23.]],\n",
       " \n",
       "          [[  56.]],\n",
       " \n",
       "          [[  12.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[ -45.]],\n",
       " \n",
       "          [[  -7.]]],\n",
       " \n",
       " \n",
       "         [[[ -67.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[  18.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -37.]],\n",
       " \n",
       "          [[  57.]],\n",
       " \n",
       "          [[  24.]]]], device='cuda:0'),\n",
       " tensor([[[[ 107.,  168.,  104.],\n",
       "           [  72.,   16.,   64.],\n",
       "           [  26.,  -87.,   18.]]],\n",
       " \n",
       " \n",
       "         [[[  65.,   72.,   92.],\n",
       "           [ 113.,  320.,  102.],\n",
       "           [  65.,  171.,   69.]]],\n",
       " \n",
       " \n",
       "         [[[ 101.,  -30.,  -52.],\n",
       "           [ 172.,  -78.,  -83.],\n",
       "           [  81.,  -70.,  -72.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -63., -118.,  -67.],\n",
       "           [  27.,  -70.,   41.],\n",
       "           [  59.,  137.,   64.]]],\n",
       " \n",
       " \n",
       "         [[[  41.,  -35.,   42.],\n",
       "           [  -7., -126.,   -4.],\n",
       "           [ 129.,  -64.,  128.]]],\n",
       " \n",
       " \n",
       "         [[[   1.,   90.,   35.],\n",
       "           [  31.,  256.,   66.],\n",
       "           [  80.,   91.,   78.]]]], device='cuda:0'),\n",
       " tensor([[[[ 29.]],\n",
       " \n",
       "          [[ 17.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -7.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          [[ 78.]]],\n",
       " \n",
       " \n",
       "         [[[ 43.]],\n",
       " \n",
       "          [[ 36.]],\n",
       " \n",
       "          [[ 22.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-43.]],\n",
       " \n",
       "          [[ 17.]],\n",
       " \n",
       "          [[ 17.]]],\n",
       " \n",
       " \n",
       "         [[[  6.]],\n",
       " \n",
       "          [[-26.]],\n",
       " \n",
       "          [[-21.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 13.]],\n",
       " \n",
       "          [[ -3.]],\n",
       " \n",
       "          [[-44.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-21.]],\n",
       " \n",
       "          [[ 28.]],\n",
       " \n",
       "          [[  7.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-47.]],\n",
       " \n",
       "          [[-16.]],\n",
       " \n",
       "          [[-83.]]],\n",
       " \n",
       " \n",
       "         [[[-73.]],\n",
       " \n",
       "          [[-11.]],\n",
       " \n",
       "          [[ 12.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          [[-38.]],\n",
       " \n",
       "          [[ 49.]]],\n",
       " \n",
       " \n",
       "         [[[-13.]],\n",
       " \n",
       "          [[ 60.]],\n",
       " \n",
       "          [[-18.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  7.]],\n",
       " \n",
       "          [[  8.]],\n",
       " \n",
       "          [[106.]]]], device='cuda:0'),\n",
       " tensor([[[[ -36.]],\n",
       " \n",
       "          [[  22.]],\n",
       " \n",
       "          [[ -12.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  80.]],\n",
       " \n",
       "          [[ -66.]],\n",
       " \n",
       "          [[   2.]]],\n",
       " \n",
       " \n",
       "         [[[ -29.]],\n",
       " \n",
       "          [[  16.]],\n",
       " \n",
       "          [[  -4.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-101.]],\n",
       " \n",
       "          [[ -59.]],\n",
       " \n",
       "          [[  -8.]]],\n",
       " \n",
       " \n",
       "         [[[  11.]],\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          [[  13.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  59.]],\n",
       " \n",
       "          [[ -41.]],\n",
       " \n",
       "          [[  31.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ -62.]],\n",
       " \n",
       "          [[ -19.]],\n",
       " \n",
       "          [[  31.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  19.]],\n",
       " \n",
       "          [[   8.]],\n",
       " \n",
       "          [[  23.]]],\n",
       " \n",
       " \n",
       "         [[[   3.]],\n",
       " \n",
       "          [[ -32.]],\n",
       " \n",
       "          [[  40.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ -40.]],\n",
       " \n",
       "          [[  32.]],\n",
       " \n",
       "          [[ -90.]]],\n",
       " \n",
       " \n",
       "         [[[  76.]],\n",
       " \n",
       "          [[ -22.]],\n",
       " \n",
       "          [[  10.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[  33.]],\n",
       " \n",
       "          [[-105.]],\n",
       " \n",
       "          [[ -12.]]]], device='cuda:0'),\n",
       " tensor([[[[  51.,  103.,   17.],\n",
       "           [ -10.,   67.,   -2.],\n",
       "           [-142.,  -41., -152.]]],\n",
       " \n",
       " \n",
       "         [[[-502., -445., -477.],\n",
       "           [-247., -268., -394.],\n",
       "           [-452., -367., -460.]]],\n",
       " \n",
       " \n",
       "         [[[ 362.,  308.,  429.],\n",
       "           [ 266.,  174.,  337.],\n",
       "           [ 361.,  296.,  414.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-247., -102., -301.],\n",
       "           [-143.,  -46., -114.],\n",
       "           [-233., -143., -262.]]],\n",
       " \n",
       " \n",
       "         [[[ 266.,  191.,  269.],\n",
       "           [ 209.,  102.,  202.],\n",
       "           [ 322.,  173.,  357.]]],\n",
       " \n",
       " \n",
       "         [[[ 380.,  261.,  418.],\n",
       "           [ 296.,  198.,  326.],\n",
       "           [ 442.,  334.,  453.]]]], device='cuda:0'),\n",
       " tensor([[[[ 1.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[ 6.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[ 2.]]],\n",
       " \n",
       " \n",
       "         [[[-1.]],\n",
       " \n",
       "          [[ 4.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[-2.]]],\n",
       " \n",
       " \n",
       "         [[[ 0.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[ 2.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[-1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-2.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-2.]]]], device='cuda:0'),\n",
       " tensor([[[[-2.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[ 7.]],\n",
       " \n",
       "          [[ 1.]]],\n",
       " \n",
       " \n",
       "         [[[-3.]],\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[-3.]]],\n",
       " \n",
       " \n",
       "         [[[-4.]],\n",
       " \n",
       "          [[ 2.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-1.]],\n",
       " \n",
       "          [[-1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.]],\n",
       " \n",
       "          [[ 5.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[-2.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          [[ 1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.]],\n",
       " \n",
       "          [[-4.]],\n",
       " \n",
       "          [[ 2.]]],\n",
       " \n",
       " \n",
       "         [[[ 3.]],\n",
       " \n",
       "          [[-3.]],\n",
       " \n",
       "          [[-2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.]],\n",
       " \n",
       "          [[-0.]],\n",
       " \n",
       "          [[-3.]]]], device='cuda:0'),\n",
       " tensor([[-2.,  4., -6.,  ..., -4., -4., -4.],\n",
       "         [-3.,  1., -1.,  ..., -3., -3.,  0.],\n",
       "         [-1.,  0., -3.,  ..., -5., -3., -0.],\n",
       "         ...,\n",
       "         [-5., -1., -3.,  ..., -2., -2.,  1.],\n",
       "         [-2.,  6.,  0.,  ..., -4.,  0., -0.],\n",
       "         [ 1.,  1.,  2.,  ..., -1., -1., -3.]], device='cuda:0')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
